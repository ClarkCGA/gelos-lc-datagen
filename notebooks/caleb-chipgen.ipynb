{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57bdd66-2d22-4c7c-ab69-6e47b8ef9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List all directories and files in the current working directory\n",
    "# for root, dirs, files in os.walk('.'):\n",
    "#     print(\"Root directory:\", root)\n",
    "#     print(\"Subdirectories:\", dirs)\n",
    "#     print(\"Files:\", files)\n",
    "#     break  # Stop after the first level to avoid printing too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a464d3-d16d-4b48-88f9-8dc05b7f23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")    #commment after first run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf645f2-1b01-4a94-a9bf-7cf315544d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import dask.distributed\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import stackstac \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from src.utils import gen_chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad1e56f6-4400-465e-a1d5-285d045430a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/benchuser/code\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "#should be /home/benchuser/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fbeaa45-046c-4e4a-9c41-8c93278fb634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"/home/benchuser/code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca29bef3-a40d-4f99-84f6-1056da9176f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentinel_2': {'collection': 'sentinel-2-l2a', 'time_ranges': ['2023-01-01/2023-03-31', '2023-04-01/2023-06-30', '2023-07-01/2023-09-30', '2023-10-01/2023-12-31'], 'cloud_cover': 1, 'bands': ['B02', 'B03', 'B04', 'B08', 'B11', 'B12'], 'resolution': 10}, 'land_cover': {'collection': 'io-lulc-annual-v02', 'year': '2023-01-02/2023-12-31'}, 'chips': {'sample_size': 100, 'chip_size': 224}, 'output': {'directory': 'notebooks/test_output_dump', 'naming_convention': 's2_{season}_{index:05}.tif'}, 'metadata': {'file': 'metadata.csv'}}\n"
     ]
    }
   ],
   "source": [
    "#config setup\n",
    "import yaml\n",
    "with open(\"notebooks/config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "print(config)  # Check the structure of the dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "057c1775-4132-4dfd-bf7d-38b449fc6ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel-2 settings\n",
    "s2_collection = config[\"sentinel_2\"][\"collection\"]\n",
    "s2_date_ranges = config[\"sentinel_2\"][\"time_ranges\"]\n",
    "s2_bands = config[\"sentinel_2\"][\"bands\"]\n",
    "s2_resolution = config[\"sentinel_2\"][\"resolution\"]\n",
    "cloud_cover_threshold = config[\"sentinel_2\"][\"cloud_cover\"]  # Max allowed cloud cover\n",
    "\n",
    "# Land Cover settings\n",
    "lc_collection = config[\"land_cover\"][\"collection\"]\n",
    "lc_year = config[\"land_cover\"][\"year\"]  # Year of LC dataset\n",
    "\n",
    "# Chip settings\n",
    "sample_size = config[\"chips\"][\"sample_size\"]  # Grid size for homogeneity check\n",
    "chip_size = config[\"chips\"][\"chip_size\"]  # Output chip size\n",
    "\n",
    "# Output settings\n",
    "output_dir = config[\"output\"][\"directory\"]\n",
    "chip_naming_convention = config[\"output\"][\"naming_convention\"]\n",
    "\n",
    "# Metadata settings\n",
    "metadata_file = config[\"metadata\"][\"file\"]\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define seasons for indexing\n",
    "seasons = [\"JFM\", \"AMJ\", \"JAS\", \"OND\"]\n",
    "\n",
    "aoi_gdf = gpd.read_file(\"data/urbans.geojson\") # or \"data/aois.geojson\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6115b35c-21fe-4f5e-9697-169bf0c0a6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:08:37,089 - distributed.scheduler - WARNING - Detected different `run_spec` for key ('getitem-f67c1a7ec2b2bc8c42f64be7a8f74565', 0, 0) between two consecutive calls to `update_graph`. This can cause failures and deadlocks down the line. Please ensure unique key names. If you are using a standard dask collections, consider releasing all the data before resubmitting another computation. More details and help can be found at https://github.com/dask/dask/issues/9888. \n",
      "Debugging information\n",
      "---------------------\n",
      "old task state: released\n",
      "old run_spec: (<function execute_task at 0x7f99b48659e0>, (('rechunk-merge-rechunk-split-reshape-getitem-f67c1a7ec2b2bc8c42f64be7a8f74565', 0, 0),), {})\n",
      "new run_spec: (<function execute_task at 0x7f99b48659e0>, (('fetch_raster_window-rechunk-merge-rechunk-split-reshape-getitem-f67c1a7ec2b2bc8c42f64be7a8f74565', 0, 0),), {})\n",
      "old token: ('tuple', (('913ceb5b5beb463a9010ec0790bc30002ca34164', []), ('tuple', (('tuple', ('rechunk-merge-rechunk-split-reshape-getitem-f67c1a7ec2b2bc8c42f64be7a8f74565', 0, 0)),)), ('dict', ())))\n",
      "new token: ('tuple', (('913ceb5b5beb463a9010ec0790bc30002ca34164', []), ('tuple', (('tuple', ('fetch_raster_window-rechunk-merge-rechunk-split-reshape-getitem-f67c1a7ec2b2bc8c42f64be7a8f74565', 0, 0)),)), ('dict', ())))\n",
      "old dependencies: {('rechunk-merge-rechunk-split-reshape-getitem-f67c1a7ec2b2bc8c42f64be7a8f74565', 0, 0)}\n",
      "new dependencies: {('fetch_raster_window-rechunk-merge-rechunk-split-reshape-getitem-f67c1a7ec2b2bc8c42f64be7a8f74565', 0, 0)}\n",
      "\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-459429' coro=<Client._gather.<locals>.wait() done, defined at /opt/conda/envs/gfm_bench/lib/python3.12/site-packages/distributed/client.py:2385> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/distributed/client.py\", line 2394, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n"
     ]
    }
   ],
   "source": [
    "#dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(n_workers=8, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c8350-dacd-4196-a5e6-b0378da78b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79ad2ce0-ca5d-4182-9e58-c071ab554609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_s2_scenes(aoi, date_range):\n",
    "    \"\"\"\n",
    "    Searches for Sentinel-2 scenes within the AOI and date range.\n",
    "    Adds debugging info to identify missing data issues.\n",
    "    \"\"\"\n",
    "\n",
    "    #print(f\"\\n Searching Sentinel-2 for AOI {aoi.geometry.bounds} during {date_range}\")\n",
    "\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "        modifier=planetary_computer.sign_inplace,\n",
    "    )\n",
    "\n",
    "    # Print the exact query parameters\n",
    "    # print(f\"Querying collection: 'sentinel-2-l2a'\")\n",
    "    #print(f\"Bounding Box: {aoi.geometry.bounds}\")\n",
    "    #print(f\"Date Range: {date_range}\")\n",
    "    # print(f\"Cloud Cover Filter: < {1}%\")\n",
    "    \n",
    "    s2_search = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        bbox=aoi.geometry.bounds, \n",
    "        datetime=date_range,\n",
    "        query={\"eo:cloud_cover\": {\"lt\": 1}},  # Fix query syntax to dictionary\n",
    "        sortby=[\"+properties.eo:cloud_cover\"],  # Sort by least cloud cover\n",
    "        max_items=10,  # Increase items to check for any available data\n",
    "    )\n",
    "\n",
    "    # Print found items\n",
    "    items = s2_search.item_collection()\n",
    "    #print(f\"Found {len(items)} Sentinel-2 scenes\")\n",
    "    \n",
    "    # Print full STAC item properties for debugging\n",
    "    # if len(items) > 0:\n",
    "    #     print(f\"First Scene ID: {items[0].id}\")\n",
    "    #     print(f\"First Scene EPSG: {items[0].properties.get('proj:epsg', 'Unknown')}\")\n",
    "    #     print(f\"Acquisition Date: {items[0].properties.get('datetime', 'Unknown')}\")\n",
    "    #     print(f\"Cloud Cover: {items[0].properties.get('eo:cloud_cover', 'Unknown')}\")\n",
    "    # else:\n",
    "    #     print(f\"No Sentinel-2 data found for this AOI and date range!\")\n",
    "\n",
    "    return list(items)  # Convert ItemCollection to a list of Items\n",
    "def search_lc_scene(bbox, lc_date_range):\n",
    "    #print(f\"Searching for Land Cover scenes within {lc_date_range} for bbox {bbox}\")\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "        modifier=planetary_computer.sign_inplace,\n",
    "    )\n",
    "    lc_search = catalog.search(\n",
    "        collections=[\"io-lulc-annual-v02\"],\n",
    "        bbox=bbox,\n",
    "        datetime=lc_date_range,\n",
    "    )\n",
    "    items = lc_search.item_collection()\n",
    "    #print(f\"Found {len(items)} Land Cover scenes\")\n",
    "    return list(items)  # Convert ItemCollection to a list of Items\n",
    "\n",
    "def stack_s2_data(s2_items, s2_bands):\n",
    "    print(\"\\nChecking available assets in Sentinel-2 items...\")\n",
    "    valid_bands = [band for band in s2_bands if all(band in item.assets for item in s2_items)]\n",
    "    try:\n",
    "        s2_stack = stackstac.stack(\n",
    "            s2_items,\n",
    "            assets=valid_bands,\n",
    "            epsg=s2_items[0].properties[\"proj:epsg\"],\n",
    "            resolution=10,\n",
    "            fill_value=np.nan,\n",
    "            dtype=\"float32\"  # Ensure time dimension is preserved\n",
    "        )\n",
    "        print(f\"Stacked Sentinel-2 bands: {list(s2_stack.coords['band'].values)}\")\n",
    "        print(f\"Number of time steps: {len(s2_stack.time)}\")\n",
    "        return s2_stack\n",
    "    except Exception as e:\n",
    "        print(f\"Error stacking Sentinel-2 data: {e}\")\n",
    "        return None\n",
    "        \n",
    "def stack_lc_data(lc_items, s2_epsg):\n",
    "    if not lc_items:\n",
    "        print(\"No Land Cover data found.\")\n",
    "        return None\n",
    "    try:\n",
    "        print(\"Stacking Land Cover images...\")\n",
    "        stacked_data = stackstac.stack(\n",
    "            lc_items,\n",
    "            dtype=np.ubyte,\n",
    "            fill_value=255,\n",
    "            sortby_date=False,\n",
    "            epsg=s2_epsg,\n",
    "            resolution=10,\n",
    "            bounds_latlon=s2_items[0].bbox,\n",
    "        ).squeeze()\n",
    "\n",
    "        stacked_data = stacked_data.chunk(chunks={\"x\": sample_size, \"y\": sample_size})\n",
    "        print(\"Stacked LC data shape:\", stacked_data.shape)\n",
    "        #print(f\"Chunk sizes: {stacked_data.chunks}\")   #uncomment for big chunk size \n",
    "\n",
    "        return stacked_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error stacking Land Cover data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def has_missing_values(array):\n",
    "    \"\"\"Check if the given array contains NaN values and print only when necessary.\"\"\"\n",
    "    has_nan = array.isnull().any().compute()\n",
    "    if has_nan:\n",
    "        print(\"Warning: Missing values detected in the chip!\")\n",
    "    return has_nan\n",
    "\n",
    "def process_chips(aoi, s2_stack, lc_stack, output_dir, global_index, chip_dict, sample_size):\n",
    "    print(f\"Processing chips for AOI at {aoi.geometry.bounds}\")\n",
    "    print(f\"Number of time steps in s2_stack: {len(s2_stack.time)}\")\n",
    "\n",
    "    def unique_class(window, axis=None, **kwargs):\n",
    "        return np.all(window == window[0, 0], axis=axis)\n",
    "\n",
    "    new_x = (lc_stack.shape[0] // sample_size) * sample_size\n",
    "    new_y = (lc_stack.shape[1] // sample_size) * sample_size\n",
    "\n",
    "    lc_stack_trimmed = lc_stack.isel(\n",
    "        x=slice(0, new_x), \n",
    "        y=slice(0, new_y)\n",
    "    ).assign_coords(\n",
    "        x=lc_stack.coords['x'].isel(x=slice(0, new_x)),\n",
    "        y=lc_stack.coords['y'].isel(y=slice(0, new_y))\n",
    "    )\n",
    "\n",
    "    lc_uniqueness = lc_stack_trimmed.coarsen(x=sample_size, y=sample_size, boundary=\"trim\").reduce(unique_class)\n",
    "\n",
    "    for t in range(len(s2_stack.time)):\n",
    "        acquisition_date = str(s2_stack.time[t].values)\n",
    "        chip_count = 0\n",
    "        print(f\"Time step {t}, acquisition date: {acquisition_date}\")\n",
    "\n",
    "        for i in range(0, lc_stack_trimmed.shape[0] - sample_size + 1, sample_size):\n",
    "            if chip_count >= 2:\n",
    "                break\n",
    "            for j in range(0, lc_stack_trimmed.shape[1] - sample_size + 1, sample_size):\n",
    "                #print(f\"i: {i}, j: {j}\")\n",
    "                if chip_count >= 2:\n",
    "                    print(f\"Reached 2 chips for time period {acquisition_date}. Moving to next time period.\")\n",
    "                      # Reset count for the next time period\n",
    "                    break  # This breaks the innermost loop\n",
    "                \n",
    "                if not lc_uniqueness.isel(x=i // sample_size, y=j // sample_size):\n",
    "                    #print(f\"Skipping non-homogeneous chip at ({i}, {j})\")\n",
    "                    continue\n",
    "\n",
    "                s2_chip = s2_stack.isel(time=t, x=slice(i, i + sample_size), y=slice(j, j + sample_size))\n",
    "                lc_chip = lc_stack_trimmed.isel(x=slice(i, i + sample_size), y=slice(j, j + sample_size))\n",
    "\n",
    "                print(f\"Checking chip at ({i}, {j}), time step {t}\")\n",
    "                if s2_chip.isnull().all() or lc_chip.isnull().all():\n",
    "                    print(f\"Skipping chip {global_index}: Empty dataset (NoDataInBounds)\")\n",
    "                    continue\n",
    "\n",
    "                chip_metadata = {\n",
    "                    \"aoi_bounds\": aoi.geometry.bounds,\n",
    "                    \"date\": acquisition_date,\n",
    "                    \"coords\": (i, j)\n",
    "                }\n",
    "\n",
    "                chip_dict[(i, j, acquisition_date)] = (s2_chip, lc_chip, chip_metadata)\n",
    "\n",
    "                chip_name = f\"s2_{global_index:05}_{acquisition_date}.tif\"\n",
    "                print(f\"Saving chip {chip_name} to {output_dir}\")\n",
    "                lc_chip.rio.to_raster(os.path.join(output_dir, f\"lc_{chip_name}\"))\n",
    "                s2_chip.squeeze().drop_vars([dim for dim in s2_chip.dims if dim not in ['band', 'x', 'y']], errors=\"ignore\").rio.to_raster(os.path.join(output_dir, chip_name))\n",
    "\n",
    "                print(f\"Saved chip {chip_name}\")\n",
    "\n",
    "                global_index += 1\n",
    "                chip_count += 1\n",
    "\n",
    "                if chip_count >= 8:\n",
    "                    print(f\"Reached 8 chips for time period {acquisition_date}. Moving to next time period.\")\n",
    "                    break\n",
    "\n",
    "    print(\"Finished processing chips.\")\n",
    "    return global_index\n",
    "\n",
    "\n",
    "def plot_chips(chip_dict, chip_indices):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    selected_chips = [chip_dict[idx] for idx in chip_indices if idx in chip_dict]\n",
    "\n",
    "    if not selected_chips:\n",
    "        print(\"No chips selected for plotting.\")\n",
    "        return\n",
    "\n",
    "    num_chips = len(selected_chips)\n",
    "    num_rows = (num_chips + 3) // 4  # Calculate the number of rows for 4 chips per row\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, 4, figsize=(20, 6 * num_rows))\n",
    "    axes = axes.flatten() if num_rows > 1 else [axes]\n",
    "\n",
    "    for idx, (s2_chip, lc_chip, metadata) in enumerate(selected_chips):\n",
    "        if s2_chip is None or lc_chip is None:\n",
    "            print(f\"Skipping chip {chip_indices[idx]}: Missing data.\")\n",
    "            continue\n",
    "\n",
    "        # Check if the 'time' dimension exists, if not, select the first time step\n",
    "        if 'time' in s2_chip.dims:\n",
    "            rgb_image = s2_chip.isel(time=0).sel(band=[\"B04\", \"B03\", \"B02\"]).transpose(\"y\", \"x\", \"band\").compute()\n",
    "        else:\n",
    "            rgb_image = s2_chip.sel(band=[\"B04\", \"B03\", \"B02\"]).transpose(\"y\", \"x\", \"band\").compute()\n",
    "\n",
    "        axes[idx].imshow(rgb_image.clip(0, 3000) / 3000)\n",
    "        axes[idx].set_title(f\"Chip {idx+1}\\nDate: {metadata['date']}\\nCoords: {metadata['coords']}\")\n",
    "        axes[idx].axis(\"off\")\n",
    "\n",
    "    for ax in axes[num_chips:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e22e52d0-740b-4e60-9709-98f358224d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing AOI: (31.20416267326229, 30.02337142235983, 31.280433633102717, 30.060612342021983)\n",
      "Querying for date range: 2023-01-01/2023-03-31\n",
      "\n",
      "Checking available assets in Sentinel-2 items...\n",
      "Stacked Sentinel-2 bands: ['B02', 'B03', 'B04', 'B08', 'B11', 'B12']\n",
      "Number of time steps: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/stackstac/prepare.py:408: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  times = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Land Cover images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/stackstac/prepare.py:408: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  times = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked LC data shape: (11272, 11273)\n",
      "Land Cover stack shape: (11272, 11273)\n",
      "Land Cover bounding box: [30.91139663, 29.72604903, 32.06723105, 30.72965025]\n",
      "Land Cover bounding box for AOI: (31.20416267326229, 30.02337142235983, 31.280433633102717, 30.060612342021983)\n",
      "Processing chips for AOI at (31.20416267326229, 30.02337142235983, 31.280433633102717, 30.060612342021983)\n",
      "Number of time steps in s2_stack: 3\n",
      "Time step 0, acquisition date: 2023-01-18T08:31:59.024000000\n",
      "Checking chip at (0, 900), time step 0\n",
      "Saving chip s2_00000_2023-01-18T08:31:59.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00000_2023-01-18T08:31:59.024000000.tif\n",
      "Checking chip at (0, 3000), time step 0\n",
      "Saving chip s2_00001_2023-01-18T08:31:59.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00001_2023-01-18T08:31:59.024000000.tif\n",
      "Reached 2 chips for time period 2023-01-18T08:31:59.024000000. Moving to next time period.\n",
      "Time step 1, acquisition date: 2023-03-04T08:28:31.024000000\n",
      "Checking chip at (0, 900), time step 1\n",
      "Saving chip s2_00002_2023-03-04T08:28:31.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00002_2023-03-04T08:28:31.024000000.tif\n",
      "Checking chip at (0, 3000), time step 1\n",
      "Saving chip s2_00003_2023-03-04T08:28:31.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00003_2023-03-04T08:28:31.024000000.tif\n",
      "Reached 2 chips for time period 2023-03-04T08:28:31.024000000. Moving to next time period.\n",
      "Time step 2, acquisition date: 2023-03-04T08:28:31.024000000\n",
      "Checking chip at (0, 900), time step 2\n",
      "Saving chip s2_00004_2023-03-04T08:28:31.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00004_2023-03-04T08:28:31.024000000.tif\n",
      "Checking chip at (0, 3000), time step 2\n",
      "Saving chip s2_00005_2023-03-04T08:28:31.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00005_2023-03-04T08:28:31.024000000.tif\n",
      "Reached 2 chips for time period 2023-03-04T08:28:31.024000000. Moving to next time period.\n",
      "Finished processing chips.\n",
      "Querying for date range: 2023-04-01/2023-06-30\n",
      "\n",
      "Checking available assets in Sentinel-2 items...\n",
      "Stacked Sentinel-2 bands: ['B02', 'B03', 'B04', 'B08', 'B11', 'B12']\n",
      "Number of time steps: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/stackstac/prepare.py:408: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  times = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Land Cover images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/stackstac/prepare.py:408: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  times = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked LC data shape: (11272, 11273)\n",
      "Land Cover stack shape: (11272, 11273)\n",
      "Land Cover bounding box: [30.91139663, 29.72604903, 32.06723105, 30.72965025]\n",
      "Land Cover bounding box for AOI: (31.20416267326229, 30.02337142235983, 31.280433633102717, 30.060612342021983)\n",
      "Processing chips for AOI at (31.20416267326229, 30.02337142235983, 31.280433633102717, 30.060612342021983)\n",
      "Number of time steps in s2_stack: 10\n",
      "Time step 0, acquisition date: 2023-04-03T08:26:01.024000000\n",
      "Checking chip at (0, 900), time step 0\n",
      "Saving chip s2_00006_2023-04-03T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00006_2023-04-03T08:26:01.024000000.tif\n",
      "Checking chip at (0, 3000), time step 0\n",
      "Saving chip s2_00007_2023-04-03T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00007_2023-04-03T08:26:01.024000000.tif\n",
      "Reached 2 chips for time period 2023-04-03T08:26:01.024000000. Moving to next time period.\n",
      "Time step 1, acquisition date: 2023-04-18T08:26:09.024000000\n",
      "Checking chip at (0, 900), time step 1\n",
      "Saving chip s2_00008_2023-04-18T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00008_2023-04-18T08:26:09.024000000.tif\n",
      "Checking chip at (0, 3000), time step 1\n",
      "Saving chip s2_00009_2023-04-18T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00009_2023-04-18T08:26:09.024000000.tif\n",
      "Reached 2 chips for time period 2023-04-18T08:26:09.024000000. Moving to next time period.\n",
      "Time step 2, acquisition date: 2023-04-18T08:26:09.024000000\n",
      "Checking chip at (0, 900), time step 2\n",
      "Saving chip s2_00010_2023-04-18T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00010_2023-04-18T08:26:09.024000000.tif\n",
      "Checking chip at (0, 3000), time step 2\n",
      "Saving chip s2_00011_2023-04-18T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00011_2023-04-18T08:26:09.024000000.tif\n",
      "Reached 2 chips for time period 2023-04-18T08:26:09.024000000. Moving to next time period.\n",
      "Time step 3, acquisition date: 2023-05-03T08:26:01.024000000\n",
      "Checking chip at (0, 900), time step 3\n",
      "Saving chip s2_00012_2023-05-03T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00012_2023-05-03T08:26:01.024000000.tif\n",
      "Checking chip at (0, 3000), time step 3\n",
      "Saving chip s2_00013_2023-05-03T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00013_2023-05-03T08:26:01.024000000.tif\n",
      "Reached 2 chips for time period 2023-05-03T08:26:01.024000000. Moving to next time period.\n",
      "Time step 4, acquisition date: 2023-05-23T08:26:01.024000000\n",
      "Checking chip at (0, 900), time step 4\n",
      "Saving chip s2_00014_2023-05-23T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00014_2023-05-23T08:26:01.024000000.tif\n",
      "Checking chip at (0, 3000), time step 4\n",
      "Saving chip s2_00015_2023-05-23T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00015_2023-05-23T08:26:01.024000000.tif\n",
      "Reached 2 chips for time period 2023-05-23T08:26:01.024000000. Moving to next time period.\n",
      "Time step 5, acquisition date: 2023-06-02T08:26:01.024000000\n",
      "Checking chip at (0, 900), time step 5\n",
      "Saving chip s2_00016_2023-06-02T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00016_2023-06-02T08:26:01.024000000.tif\n",
      "Checking chip at (0, 3000), time step 5\n",
      "Saving chip s2_00017_2023-06-02T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00017_2023-06-02T08:26:01.024000000.tif\n",
      "Reached 2 chips for time period 2023-06-02T08:26:01.024000000. Moving to next time period.\n",
      "Time step 6, acquisition date: 2023-06-12T08:26:01.024000000\n",
      "Checking chip at (0, 900), time step 6\n",
      "Saving chip s2_00018_2023-06-12T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00018_2023-06-12T08:26:01.024000000.tif\n",
      "Checking chip at (0, 3000), time step 6\n",
      "Saving chip s2_00019_2023-06-12T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00019_2023-06-12T08:26:01.024000000.tif\n",
      "Reached 2 chips for time period 2023-06-12T08:26:01.024000000. Moving to next time period.\n",
      "Time step 7, acquisition date: 2023-06-17T08:26:09.024000000\n",
      "Checking chip at (0, 900), time step 7\n",
      "Saving chip s2_00020_2023-06-17T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00020_2023-06-17T08:26:09.024000000.tif\n",
      "Checking chip at (0, 3000), time step 7\n",
      "Saving chip s2_00021_2023-06-17T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00021_2023-06-17T08:26:09.024000000.tif\n",
      "Reached 2 chips for time period 2023-06-17T08:26:09.024000000. Moving to next time period.\n",
      "Time step 8, acquisition date: 2023-06-22T08:26:01.024000000\n",
      "Checking chip at (0, 900), time step 8\n",
      "Saving chip s2_00022_2023-06-22T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00022_2023-06-22T08:26:01.024000000.tif\n",
      "Checking chip at (0, 3000), time step 8\n",
      "Saving chip s2_00023_2023-06-22T08:26:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00023_2023-06-22T08:26:01.024000000.tif\n",
      "Reached 2 chips for time period 2023-06-22T08:26:01.024000000. Moving to next time period.\n",
      "Time step 9, acquisition date: 2023-06-27T08:26:09.024000000\n",
      "Checking chip at (0, 900), time step 9\n",
      "Saving chip s2_00024_2023-06-27T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00024_2023-06-27T08:26:09.024000000.tif\n",
      "Checking chip at (0, 3000), time step 9\n",
      "Saving chip s2_00025_2023-06-27T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00025_2023-06-27T08:26:09.024000000.tif\n",
      "Reached 2 chips for time period 2023-06-27T08:26:09.024000000. Moving to next time period.\n",
      "Finished processing chips.\n",
      "Querying for date range: 2023-07-01/2023-09-30\n",
      "\n",
      "Checking available assets in Sentinel-2 items...\n",
      "Stacked Sentinel-2 bands: ['B02', 'B03', 'B04', 'B08', 'B11', 'B12']\n",
      "Number of time steps: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/stackstac/prepare.py:408: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  times = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Land Cover images...\n",
      "Stacked LC data shape: (11272, 11273)\n",
      "Land Cover stack shape: (11272, 11273)\n",
      "Land Cover bounding box: [30.91139663, 29.72604903, 32.06723105, 30.72965025]\n",
      "Land Cover bounding box for AOI: (31.20416267326229, 30.02337142235983, 31.280433633102717, 30.060612342021983)\n",
      "Processing chips for AOI at (31.20416267326229, 30.02337142235983, 31.280433633102717, 30.060612342021983)\n",
      "Number of time steps in s2_stack: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/stackstac/prepare.py:408: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  times = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0, acquisition date: 2023-07-17T08:26:09.024000000\n",
      "Checking chip at (0, 900), time step 0\n",
      "Saving chip s2_00026_2023-07-17T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00026_2023-07-17T08:26:09.024000000.tif\n",
      "Checking chip at (0, 3000), time step 0\n",
      "Saving chip s2_00027_2023-07-17T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00027_2023-07-17T08:26:09.024000000.tif\n",
      "Reached 2 chips for time period 2023-07-17T08:26:09.024000000. Moving to next time period.\n",
      "Time step 1, acquisition date: 2023-07-22T08:26:11.024000000\n",
      "Checking chip at (0, 900), time step 1\n",
      "Saving chip s2_00028_2023-07-22T08:26:11.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00028_2023-07-22T08:26:11.024000000.tif\n",
      "Checking chip at (0, 3000), time step 1\n",
      "Saving chip s2_00029_2023-07-22T08:26:11.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00029_2023-07-22T08:26:11.024000000.tif\n",
      "Reached 2 chips for time period 2023-07-22T08:26:11.024000000. Moving to next time period.\n",
      "Time step 2, acquisition date: 2023-08-01T08:26:11.024000000\n",
      "Checking chip at (0, 900), time step 2\n",
      "Saving chip s2_00030_2023-08-01T08:26:11.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00030_2023-08-01T08:26:11.024000000.tif\n",
      "Checking chip at (0, 3000), time step 2\n",
      "Saving chip s2_00031_2023-08-01T08:26:11.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00031_2023-08-01T08:26:11.024000000.tif\n",
      "Reached 2 chips for time period 2023-08-01T08:26:11.024000000. Moving to next time period.\n",
      "Time step 3, acquisition date: 2023-08-06T08:26:09.024000000\n",
      "Checking chip at (0, 900), time step 3\n",
      "Saving chip s2_00032_2023-08-06T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00032_2023-08-06T08:26:09.024000000.tif\n",
      "Checking chip at (0, 3000), time step 3\n",
      "Saving chip s2_00033_2023-08-06T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00033_2023-08-06T08:26:09.024000000.tif\n",
      "Reached 2 chips for time period 2023-08-06T08:26:09.024000000. Moving to next time period.\n",
      "Time step 4, acquisition date: 2023-08-26T08:26:09.024000000\n",
      "Checking chip at (0, 900), time step 4\n",
      "Saving chip s2_00034_2023-08-26T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00034_2023-08-26T08:26:09.024000000.tif\n",
      "Checking chip at (0, 3000), time step 4\n",
      "Saving chip s2_00035_2023-08-26T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00035_2023-08-26T08:26:09.024000000.tif\n",
      "Reached 2 chips for time period 2023-08-26T08:26:09.024000000. Moving to next time period.\n",
      "Time step 5, acquisition date: 2023-08-31T08:26:11.024000000\n",
      "Checking chip at (0, 900), time step 5\n",
      "Saving chip s2_00036_2023-08-31T08:26:11.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00036_2023-08-31T08:26:11.024000000.tif\n",
      "Checking chip at (0, 3000), time step 5\n",
      "Saving chip s2_00037_2023-08-31T08:26:11.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00037_2023-08-31T08:26:11.024000000.tif\n",
      "Reached 2 chips for time period 2023-08-31T08:26:11.024000000. Moving to next time period.\n",
      "Time step 6, acquisition date: 2023-09-05T08:26:09.024000000\n",
      "Checking chip at (0, 900), time step 6\n",
      "Saving chip s2_00038_2023-09-05T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00038_2023-09-05T08:26:09.024000000.tif\n",
      "Checking chip at (0, 3000), time step 6\n",
      "Saving chip s2_00039_2023-09-05T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00039_2023-09-05T08:26:09.024000000.tif\n",
      "Reached 2 chips for time period 2023-09-05T08:26:09.024000000. Moving to next time period.\n",
      "Time step 7, acquisition date: 2023-09-10T08:26:11.024000000\n",
      "Checking chip at (0, 900), time step 7\n",
      "Saving chip s2_00040_2023-09-10T08:26:11.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00040_2023-09-10T08:26:11.024000000.tif\n",
      "Checking chip at (0, 3000), time step 7\n",
      "Saving chip s2_00041_2023-09-10T08:26:11.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00041_2023-09-10T08:26:11.024000000.tif\n",
      "Reached 2 chips for time period 2023-09-10T08:26:11.024000000. Moving to next time period.\n",
      "Time step 8, acquisition date: 2023-09-15T08:26:09.024000000\n",
      "Checking chip at (0, 900), time step 8\n",
      "Saving chip s2_00042_2023-09-15T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00042_2023-09-15T08:26:09.024000000.tif\n",
      "Checking chip at (0, 3000), time step 8\n",
      "Saving chip s2_00043_2023-09-15T08:26:09.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00043_2023-09-15T08:26:09.024000000.tif\n",
      "Reached 2 chips for time period 2023-09-15T08:26:09.024000000. Moving to next time period.\n",
      "Time step 9, acquisition date: 2023-09-25T08:26:59.024000000\n",
      "Checking chip at (0, 900), time step 9\n",
      "Saving chip s2_00044_2023-09-25T08:26:59.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00044_2023-09-25T08:26:59.024000000.tif\n",
      "Checking chip at (0, 3000), time step 9\n",
      "Saving chip s2_00045_2023-09-25T08:26:59.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00045_2023-09-25T08:26:59.024000000.tif\n",
      "Reached 2 chips for time period 2023-09-25T08:26:59.024000000. Moving to next time period.\n",
      "Finished processing chips.\n",
      "Querying for date range: 2023-10-01/2023-12-31\n",
      "\n",
      "Checking available assets in Sentinel-2 items...\n",
      "Stacked Sentinel-2 bands: ['B02', 'B03', 'B04', 'B08', 'B11', 'B12']\n",
      "Number of time steps: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/stackstac/prepare.py:408: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  times = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Land Cover images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/stackstac/prepare.py:408: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  times = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked LC data shape: (11272, 11273)\n",
      "Land Cover stack shape: (11272, 11273)\n",
      "Land Cover bounding box: [30.91139663, 29.72604903, 32.06723105, 30.72965025]\n",
      "Land Cover bounding box for AOI: (31.20416267326229, 30.02337142235983, 31.280433633102717, 30.060612342021983)\n",
      "Processing chips for AOI at (31.20416267326229, 30.02337142235983, 31.280433633102717, 30.060612342021983)\n",
      "Number of time steps in s2_stack: 5\n",
      "Time step 0, acquisition date: 2023-10-20T08:29:41.024000000\n",
      "Checking chip at (0, 900), time step 0\n",
      "Saving chip s2_00046_2023-10-20T08:29:41.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00046_2023-10-20T08:29:41.024000000.tif\n",
      "Checking chip at (0, 3000), time step 0\n",
      "Saving chip s2_00047_2023-10-20T08:29:41.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00047_2023-10-20T08:29:41.024000000.tif\n",
      "Reached 2 chips for time period 2023-10-20T08:29:41.024000000. Moving to next time period.\n",
      "Time step 1, acquisition date: 2023-10-25T08:29:29.024000000\n",
      "Checking chip at (0, 900), time step 1\n",
      "Saving chip s2_00048_2023-10-25T08:29:29.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00048_2023-10-25T08:29:29.024000000.tif\n",
      "Checking chip at (0, 3000), time step 1\n",
      "Saving chip s2_00049_2023-10-25T08:29:29.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00049_2023-10-25T08:29:29.024000000.tif\n",
      "Reached 2 chips for time period 2023-10-25T08:29:29.024000000. Moving to next time period.\n",
      "Time step 2, acquisition date: 2023-11-04T08:30:29.024000000\n",
      "Checking chip at (0, 900), time step 2\n",
      "Saving chip s2_00050_2023-11-04T08:30:29.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00050_2023-11-04T08:30:29.024000000.tif\n",
      "Checking chip at (0, 3000), time step 2\n",
      "Saving chip s2_00051_2023-11-04T08:30:29.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00051_2023-11-04T08:30:29.024000000.tif\n",
      "Reached 2 chips for time period 2023-11-04T08:30:29.024000000. Moving to next time period.\n",
      "Time step 3, acquisition date: 2023-11-29T08:33:01.024000000\n",
      "Checking chip at (0, 900), time step 3\n",
      "Saving chip s2_00052_2023-11-29T08:33:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00052_2023-11-29T08:33:01.024000000.tif\n",
      "Checking chip at (0, 3000), time step 3\n",
      "Saving chip s2_00053_2023-11-29T08:33:01.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00053_2023-11-29T08:33:01.024000000.tif\n",
      "Reached 2 chips for time period 2023-11-29T08:33:01.024000000. Moving to next time period.\n",
      "Time step 4, acquisition date: 2023-12-14T08:32:49.024000000\n",
      "Checking chip at (0, 900), time step 4\n",
      "Saving chip s2_00054_2023-12-14T08:32:49.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00054_2023-12-14T08:32:49.024000000.tif\n",
      "Checking chip at (0, 3000), time step 4\n",
      "Saving chip s2_00055_2023-12-14T08:32:49.024000000.tif to notebooks/test_output_dump\n",
      "Saved chip s2_00055_2023-12-14T08:32:49.024000000.tif\n",
      "Reached 2 chips for time period 2023-12-14T08:32:49.024000000. Moving to next time period.\n",
      "Finished processing chips.\n",
      "\n",
      "Processing AOI: (28.84773759372314, 41.00724457843606, 28.92438317781108, 41.04136515505064)\n",
      "Querying for date range: 2023-01-01/2023-03-31\n",
      "\n",
      "Checking available assets in Sentinel-2 items...\n",
      "Stacked Sentinel-2 bands: ['B02', 'B03', 'B04', 'B08', 'B11', 'B12']\n",
      "Number of time steps: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/stackstac/prepare.py:408: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  times = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Land Cover images...\n",
      "Stacked LC data shape: (11350, 10215)\n",
      "Land Cover stack shape: (11350, 10215)\n",
      "Land Cover bounding box: [28.32859925, 40.53618553, 29.51453839, 41.53860487]\n",
      "Land Cover bounding box for AOI: (28.84773759372314, 41.00724457843606, 28.92438317781108, 41.04136515505064)\n",
      "Processing chips for AOI at (28.84773759372314, 41.00724457843606, 28.92438317781108, 41.04136515505064)\n",
      "Number of time steps in s2_stack: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/stackstac/prepare.py:408: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  times = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0, acquisition date: 2023-01-09T08:53:31.024000000\n",
      "Checking chip at (0, 0), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 100), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 200), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 300), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 400), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 500), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 600), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 700), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 800), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 5600), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 5700), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 5800), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 5900), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 6000), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 6100), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 6200), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 6300), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 6400), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 6500), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 6600), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 6700), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 6800), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 6900), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 7000), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 7100), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 7200), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 7300), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 7400), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 7500), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 7600), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 7700), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 7800), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 7900), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 8000), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 8100), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 8200), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 8300), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 8400), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 8500), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 8600), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 8700), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 8800), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 8900), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 9000), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 9100), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 9200), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 9300), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 9400), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 9500), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 9600), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 9700), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 9800), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 9900), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 10000), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (0, 10100), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 0), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 100), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 200), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 300), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 400), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 500), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 600), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 700), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 800), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 5600), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 5700), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 5800), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 5900), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 6000), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 6100), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 6200), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 6300), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 6400), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 6500), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 6600), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 6700), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 6800), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 6900), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 7000), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n",
      "Checking chip at (100, 7100), time step 0\n",
      "Skipping chip 56: Empty dataset (NoDataInBounds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:17:56,819 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('fetch_raster_window-rechunk-merge-rechunk-split-reshape-getitem-0fef8e935d649aaa9a3b204a06c5b752', 1, 0))\" coro=<Worker.execute() done, defined at /opt/conda/envs/gfm_bench/lib/python3.12/site-packages/distributed/worker_state_machine.py:3609>> ended with CancelledError\n",
      "2025-02-15 21:17:56,821 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('fetch_raster_window-getitem-rechunk-merge-rechunk-split-reshape-04f9d13401e57653da59150694e4c4b5', 72, 0, 1, 0))\" coro=<Worker.execute() done, defined at /opt/conda/envs/gfm_bench/lib/python3.12/site-packages/distributed/worker_state_machine.py:3609>> ended with CancelledError\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLand Cover bounding box for AOI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maoi\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mbounds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Debug: print AOI bounding box\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Process chips after confirming the data is available\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m global_index \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_chips\u001b[49m\u001b[43m(\u001b[49m\u001b[43maoi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2_stack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlc_stack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchip_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 146\u001b[0m, in \u001b[0;36mprocess_chips\u001b[0;34m(aoi, s2_stack, lc_stack, output_dir, global_index, chip_dict, sample_size)\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[38;5;66;03m# Reset count for the next time period\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# This breaks the innermost loop\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lc_uniqueness\u001b[38;5;241m.\u001b[39misel(x\u001b[38;5;241m=\u001b[39mi \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m sample_size, y\u001b[38;5;241m=\u001b[39mj \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m sample_size):\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m#print(f\"Skipping non-homogeneous chip at ({i}, {j})\")\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    150\u001b[0m s2_chip \u001b[38;5;241m=\u001b[39m s2_stack\u001b[38;5;241m.\u001b[39misel(time\u001b[38;5;241m=\u001b[39mt, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m sample_size), y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(j, j \u001b[38;5;241m+\u001b[39m sample_size))\n",
      "File \u001b[0;32m/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/xarray/core/common.py:154\u001b[0m, in \u001b[0;36mAbstractArray.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/xarray/core/dataarray.py:814\u001b[0m, in \u001b[0;36mDataArray.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    The array's data converted to numpy.ndarray.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m    to this array may be reflected in the DataArray as well.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/xarray/core/variable.py:566\u001b[0m, in \u001b[0;36mVariable.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    565\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/xarray/core/variable.py:363\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_array_or_item\u001b[39m(data):\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/dask/array/core.py:1696\u001b[0m, in \u001b[0;36mArray.__array__\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1696\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m   1698\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(dtype)\n",
      "File \u001b[0;32m/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/dask/base.py:372\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/envs/gfm_bench/lib/python3.12/site-packages/dask/base.py:660\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 660\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/opt/conda/envs/gfm_bench/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/envs/gfm_bench/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_index = 0\n",
    "chip_dict = {}\n",
    "for index, aoi in aoi_gdf.iterrows():\n",
    "    print(f\"\\nProcessing AOI: {aoi.geometry.bounds}\")  # Debug: print AOI bounds\n",
    "\n",
    "    for date_range in s2_date_ranges:\n",
    "        print(f\"Querying for date range: {date_range}\")  # Debug: print date range being processed\n",
    "       \n",
    "        # Debugging: Check if Sentinel-2 items are found for the AOI and date range\n",
    "        s2_items = search_s2_scenes(aoi, date_range)\n",
    "        if not s2_items:\n",
    "            print(f\"No Sentinel-2 scenes found for AOI {aoi.geometry.bounds} and date range {date_range}\")\n",
    "            continue\n",
    "       \n",
    "        expected_bands = [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"B12\"]\n",
    "        s2_stack = stack_s2_data(s2_items, expected_bands)\n",
    "       \n",
    "        # Debugging: Check if Sentinel-2 stack is created correctly\n",
    "        if s2_stack is None:\n",
    "            print(f\"Failed to stack Sentinel-2 bands for AOI {aoi.geometry.bounds} and date range {date_range}\")\n",
    "            continue\n",
    "\n",
    "        # Debugging: Check if Land Cover items are found for the AOI and date range\n",
    "        lc_items = search_lc_scene(s2_items[0].bbox, lc_year)\n",
    "        if not lc_items:\n",
    "            print(f\"No Land Cover data found for AOI {aoi.geometry.bounds} and date range {date_range}\")\n",
    "            continue\n",
    "       \n",
    "        # Debugging: Check Land Cover data dimensions and bounds\n",
    "        lc_stack = stack_lc_data(lc_items, s2_stack.rio.crs.to_epsg())\n",
    "        if lc_stack is None:\n",
    "            print(f\"Failed to stack Land Cover data for AOI {aoi.geometry.bounds} and date range {date_range}\")\n",
    "            continue\n",
    "        print(f\"Land Cover stack shape: {lc_stack.shape}\")  # Debug: check shape of the LC stack\n",
    "\n",
    "        # Debugging: Check bounding box of the Land Cover data and Sentinel-2 data\n",
    "        print(f\"Land Cover bounding box: {s2_items[0].bbox}\")  # Debug: print bounding box for Sentinel-2 scene\n",
    "        print(f\"Land Cover bounding box for AOI: {aoi.geometry.bounds}\")  # Debug: print AOI bounding box\n",
    "\n",
    "        # Process chips after confirming the data is available\n",
    "        global_index = process_chips(aoi, s2_stack, lc_stack, output_dir, global_index, chip_dict, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d558c00-9b9d-4d4d-b2e0-4c1b3b894ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chip_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16447a-f5a8-44ba-9e82-017e18bd1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(chip_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8264d8-cfa7-4ba6-96a0-24ff45155521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# List of valid chip indices in chip_dict\n",
    "valid_chip_indices = list(chip_dict.keys())\n",
    "\n",
    "# Map your indices to the actual (i, j, acquisition_date) keys\n",
    "selected_indices = []\n",
    "for idx in [1, 20, 40, 50]:\n",
    "    # This assumes that you want to select based on the index of chips, i.e., global index\n",
    "    if idx < len(valid_chip_indices):\n",
    "        selected_indices.append(valid_chip_indices[idx])\n",
    "\n",
    "# Plot the selected chips\n",
    "plot_chips(chip_dict, selected_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc4167d-b5d1-48d4-883d-f5cc4dcbd1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(s2_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f913f5-d13b-40a6-8b6c-496f6ded3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(s2_stack.isel(band=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af5a4d-3fc5-41c0-8141-2a516b026e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"First four chips content:\", first_four_chips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dbbc00-0965-493e-9567-1f0e556f6b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(chip_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb7a68-73e3-4c86-97dc-50ec125e3791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
