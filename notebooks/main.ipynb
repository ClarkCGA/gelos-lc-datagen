{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d5f12a-bb8e-4846-b696-1bd19f31c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "703e11f5-544d-414b-92ea-26baa6cb2cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dask.distributed\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "from src.utils import search_s2_scenes, search_lc_scene, stack_s2_data, stack_lc_data, unique_class, missing_values, gen_chips\n",
    "import pystac\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5305e5b8-812e-4fde-80cd-3d51cc3979ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3988ac7-764b-4f5f-af05-f70d2a12a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_gdf = gpd.read_file(\"data/all_aois.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e8dae-3733-4d16-bc15-e6f7214f7de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(n_workers=8, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b90881-1023-49bd-89bd-9f764872f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11988702-1648-400d-894c-796738f3028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chips(s2_stack, lc_stack, epsg, sample_size, chip_size, global_index, metadata_df):\n",
    "    \n",
    "    lc_stack = lc_stack.compute()\n",
    "    \n",
    "    lc_uniqueness = lc_stack.coarsen(x = sample_size,\n",
    "                                     y = sample_size,\n",
    "                                     boundary = \"trim\"\n",
    "                                    ).reduce(unique_class)\n",
    "    lc_uniqueness[0, :] = False\n",
    "    lc_uniqueness[-1, :] = False\n",
    "    lc_uniqueness[:, 0] = False\n",
    "    lc_uniqueness[:, -1] = False\n",
    "\n",
    "    ys, xs = np.where(lc_uniqueness)\n",
    "    print(\"Loading s2_stack\")\n",
    "    s2_stack = s2_stack.compute()\n",
    "    \n",
    "    for index in range(0, len(ys)):\n",
    "        y = ys[index]\n",
    "        x = xs[index]\n",
    "    \n",
    "            \n",
    "        x_coords = slice((x) * sample_size - int((chip_size - sample_size)/2), (x + 1) * sample_size + int((chip_size - sample_size)/2))\n",
    "        y_coords = slice((y) * sample_size - int((chip_size - sample_size)/2), (y + 1) * sample_size + int((chip_size - sample_size)/2))    \n",
    "        \n",
    "        s2_array = s2_stack.isel(x = x_coords, y = y_coords)\n",
    "        s2_array.rio.write_crs(f\"epsg:{epsg}\", inplace=True)\n",
    "        s2_array = s2_array.where((s2_array.x >= s2_stack.x[(x) * sample_size]) &\n",
    "                                  (s2_array.x < s2_stack.x[(x + 1) * sample_size]) & \n",
    "                                  (s2_array.y <= s2_stack.y[(y) * sample_size]) &\n",
    "                                  (s2_array.y > s2_stack.y[(y + 1) * sample_size])\n",
    "                                 )\n",
    "        \n",
    "        if missing_values(s2_array, chip_size, sample_size):\n",
    "            print(f\"Skipping chip at index {index}\")\n",
    "            continue        \n",
    "        \n",
    "        s2_array = s2_array.fillna(-999)\n",
    "        s2_array = s2_array.rio.write_nodata(-999)\n",
    "        s2_array = s2_array.astype(np.dtype(np.int16))\n",
    "        s2_array = s2_array.rename(\"s2\")\n",
    "        \n",
    "\n",
    "                \n",
    "        lc_array = lc_stack.isel(x = x_coords, y = y_coords)\n",
    "        lc_array.rio.write_crs(f\"epsg:{epsg}\", inplace=True)\n",
    "        lc_array = lc_array.where((lc_array.x >= lc_stack.x[(x) * sample_size]) &\n",
    "                                  (lc_array.x < lc_stack.x[(x + 1) * sample_size]) & \n",
    "                                  (lc_array.y <= lc_stack.y[(y) * sample_size] ) &\n",
    "                                  (lc_array.y > lc_stack.y[(y + 1) * sample_size])\n",
    "                                 )\n",
    "        \n",
    "        if missing_values(lc_array, chip_size, sample_size):\n",
    "            print(f\"Skipping chip at index {index}\")\n",
    "            continue\n",
    "            \n",
    "        lc_array = lc_array.fillna(-1)\n",
    "        lc_array = lc_array.rio.write_nodata(-1)\n",
    "        lc_array = lc_array.astype(np.dtype(np.int16))\n",
    "        lc_array = lc_array.rename(\"lc\")\n",
    "        gen_status = gen_chips(s2_array, lc_array, global_index)\n",
    "        if gen_status:\n",
    "            metadata_df = pd.concat([pd.DataFrame([[global_index,\n",
    "                                                    lc_array.mean(skipna=True).compute().data,\n",
    "                                                    s2_stack.x[(x) * sample_size].data,\n",
    "                                                    s2_stack.y[(y) * sample_size].data,\n",
    "                                                    epsg]\n",
    "                                                  ],\n",
    "                                                  columns=metadata_df.columns\n",
    "                                                 ),\n",
    "                                     metadata_df],\n",
    "                                    ignore_index=True\n",
    "                                   )\n",
    "            global_index += 1\n",
    "    \n",
    "    return global_index, metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae971c5-2245-4ac9-88c6-a65e4d453427",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_index = 0\n",
    "metadata_df = pd.DataFrame(columns=[\"chip_id\", \"lc\", \"tlc_x\", \"tlc_y\", \"epsg\"])\n",
    "for index, aoi in aoi_gdf.iterrows():\n",
    "    print(f\"\\nProcessing AOI at index {index}\")\n",
    "    \n",
    "    aoi_bounds = aoi['geometry'].bounds\n",
    "    s2_items = pystac.item_collection.ItemCollection([])\n",
    "    for date_range in config[\"sentinel_2\"][\"time_ranges\"]:        \n",
    "        s2_items_season = search_s2_scenes(aoi, date_range, catalog, config)\n",
    "        s2_items += s2_items_season\n",
    "\n",
    "    if len(s2_items)<4:\n",
    "        print(f\"Missing Sentinel-2 scenes for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "        \n",
    "\n",
    "    s2_stack = stack_s2_data(s2_items, config)\n",
    "    try:\n",
    "        epsg = s2_items[0].properties[\"proj:epsg\"]\n",
    "    except:\n",
    "        epsg = int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])\n",
    "        \n",
    "    if s2_stack is None:\n",
    "        print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "\n",
    "    lc_items = search_lc_scene(aoi_bounds, catalog, config)\n",
    "    if not lc_items:\n",
    "        print(f\"No Land Cover data found for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "    \n",
    "    lc_stack = stack_lc_data(lc_items, s2_stack.rio.crs.to_epsg(), s2_items[0].bbox, config)\n",
    "    if lc_stack is None:\n",
    "        print(f\"Failed to stack Land Cover data for AOI {aoi_bounds} and date range {date_range}\")\n",
    "        continue\n",
    "\n",
    "    global_index, metadata_df = process_chips(s2_stack,\n",
    "                                              lc_stack,\n",
    "                                              epsg,\n",
    "                                              config[\"chips\"][\"sample_size\"],\n",
    "                                              config[\"chips\"][\"chip_size\"],\n",
    "                                              global_index,\n",
    "                                              metadata_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b9a89-a19d-4b0c-b128-9e554ea09048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_df.to_csv('/home/benchuser/data/metadata_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253a772-0d85-4e2f-9396-48c38c40f814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfm_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
