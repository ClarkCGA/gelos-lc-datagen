{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5f12a-bb8e-4846-b696-1bd19f31c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e11f5-544d-414b-92ea-26baa6cb2cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dask.distributed\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "from src.utils import search_s2_scenes, search_lc_scene, stack_s2_data, stack_lc_data, unique_class, missing_values, gen_chips\n",
    "import pystac\n",
    "import yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5305e5b8-812e-4fde-80cd-3d51cc3979ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608cc1a8-26b9-41ef-a623-c81fc1b1f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sentinel-2 settings\n",
    "# # s2_collection = config[\"sentinel_2\"][\"collection\"]\n",
    "# # s2_date_ranges = config[\"sentinel_2\"][\"time_ranges\"]\n",
    "# # s2_bands = config[\"sentinel_2\"][\"bands\"]\n",
    "# s2_resolution = config[\"sentinel_2\"][\"resolution\"]\n",
    "# # cloud_cover_threshold = config[\"sentinel_2\"][\"cloud_cover\"]  # Max allowed cloud cover\n",
    "\n",
    "# # Land Cover settings\n",
    "# # lc_collection = config[\"land_cover\"][\"collection\"]\n",
    "# # lc_year = config[\"land_cover\"][\"year\"]  # Year of LC dataset\n",
    "\n",
    "# # Chip settings\n",
    "# # sample_size = config[\"chips\"][\"sample_size\"]  # Grid size for homogeneity check\n",
    "# chip_size = config[\"chips\"][\"chip_size\"]  # Output chip size\n",
    "\n",
    "# # Output settings\n",
    "\n",
    "# chip_naming_convention = config[\"output\"][\"naming_convention\"]\n",
    "\n",
    "# # Metadata settings\n",
    "# metadata_file = config[\"metadata\"][\"file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3988ac7-764b-4f5f-af05-f70d2a12a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the output directory exists\n",
    "output_dir = config[\"output\"][\"directory\"]\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define seasons for indexing\n",
    "seasons = [\"JFM\", \"AMJ\", \"JAS\", \"OND\"]\n",
    "\n",
    "aoi_gdf = gpd.read_file(\"data/urbans.geojson\") # or \"data/aois.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e8dae-3733-4d16-bc15-e6f7214f7de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(n_workers=8, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b90881-1023-49bd-89bd-9f764872f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae971c5-2245-4ac9-88c6-a65e4d453427",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_index = 0\n",
    "chip_dict = {}\n",
    "for index, aoi in aoi_gdf.iterrows():\n",
    "    print(f\"\\nProcessing AOI at index {index}\")\n",
    "    \n",
    "    # Get the bounding box from the geometry of the AOI\n",
    "    aoi_bounds = aoi['geometry'].bounds\n",
    "    # print(f\"AOI Geometry Bounds: {aoi_bounds}\")  # Print the bounding box for the AOI\n",
    "    s2_items = pystac.item_collection.ItemCollection([])\n",
    "    for date_range in config[\"sentinel_2\"][\"time_ranges\"]:\n",
    "        print(f\"Querying for date range: {date_range}\")\n",
    "        \n",
    "        s2_items_season = search_s2_scenes(aoi, date_range, catalog, config)\n",
    "        if not s2_items_season:\n",
    "            print(f\"No Sentinel-2 scenes found for AOI {aoi_bounds} and date range {date_range}\")\n",
    "            continue\n",
    "\n",
    "        s2_items += s2_items_season\n",
    "        \n",
    "\n",
    "    s2_stack = stack_s2_data(s2_items, config)\n",
    "    if s2_stack is None:\n",
    "        print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds} and date range {date_range}\")\n",
    "        continue\n",
    "\n",
    "    # Search Land Cover data for the AOI's bounding box\n",
    "    lc_items = search_lc_scene(aoi_bounds, catalog, config)\n",
    "    if not lc_items:\n",
    "        print(f\"No Land Cover data found for AOI {aoi_bounds} and date range {date_range}\")\n",
    "        continue\n",
    "    \n",
    "    lc_stack = stack_lc_data(lc_items, s2_stack.rio.crs.to_epsg(), s2_items[0].bbox, config)\n",
    "    if lc_stack is None:\n",
    "        print(f\"Failed to stack Land Cover data for AOI {aoi_bounds} and date range {date_range}\")\n",
    "        continue\n",
    "    print(f\"Land Cover stack shape: {lc_stack.shape}\")\n",
    "    break\n",
    "\n",
    "    #     # Process chips after confirming the data is available\n",
    "    #     global_index = process_chips(aoi, s2_stack, lc_stack, output_dir, global_index, chip_dict, sample_size)\n",
    "    # print(\"stopping after 1st AOI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac4bb89-29fe-4a4a-8f76-5870a7ec8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_uniqueness = lc_stack.coarsen(x = config[\"chips\"][\"sample_size\"],\n",
    "                                 y = config[\"chips\"][\"sample_size\"],\n",
    "                                 boundary = \"trim\"\n",
    "                                ).reduce(unique_class).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e6008-5f00-4373-9a4b-44e58dcc8b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_uniqueness[0, :] = False\n",
    "lc_uniqueness[-1, :] = False\n",
    "lc_uniqueness[:, 0] = False\n",
    "lc_uniqueness[:, -1] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e23cce-f873-44e9-a724-6add2689a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = np.where(lc_uniqueness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b9a89-a19d-4b0c-b128-9e554ea09048",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0, len(rows)):\n",
    "    print(index)\n",
    "    i = rows[index]\n",
    "    j = cols[index]\n",
    "        \n",
    "    x_coords = slice((i) * config[\"chips\"][\"sample_size\"] - int((config[\"chips\"][\"chip_size\"] - config[\"chips\"][\"sample_size\"])/2), (i + 1) * config[\"chips\"][\"sample_size\"] + int((config[\"chips\"][\"chip_size\"] - config[\"chips\"][\"sample_size\"])/2))\n",
    "    y_coords = slice((j) * config[\"chips\"][\"sample_size\"] - int((config[\"chips\"][\"chip_size\"] - config[\"chips\"][\"sample_size\"])/2), (j + 1) * config[\"chips\"][\"sample_size\"] + int((config[\"chips\"][\"chip_size\"] - config[\"chips\"][\"sample_size\"])/2))    \n",
    "    \n",
    "    s2_array = s2_stack.isel(x = x_coords, y = y_coords)\n",
    "    s2_array.rio.write_crs(f\"epsg:{int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])}\", inplace=True)\n",
    "    s2_array = s2_array.where((s2_array.x >= s2_stack.x[(i - 1) * config[\"chips\"][\"sample_size\"]]) &\n",
    "                              (s2_array.x < s2_stack.x[i * config[\"chips\"][\"sample_size\"]]) & \n",
    "                              (s2_array.y <= s2_stack.y[(j - 1) * config[\"chips\"][\"sample_size\"]] ) &\n",
    "                              (s2_array.y > s2_stack.y[j * config[\"chips\"][\"sample_size\"]])\n",
    "                             )\n",
    "    \n",
    "    s2_array = s2_array.fillna(-999)\n",
    "    s2_array = s2_array.rio.write_nodata(-999)\n",
    "    s2_array = s2_array.astype(np.dtype(np.int16))\n",
    "    s2_array = s2_array.rename(\"s2\")\n",
    "    s2_array = s2_array.compute()\n",
    "    \n",
    "    if np.sum(s2_array<0)>0:\n",
    "        continue\n",
    "        \n",
    "    lc_array = lc_stack.isel(x = x_coords, y = y_coords)\n",
    "    lc_array.rio.write_crs(f\"epsg:{int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])}\", inplace=True)\n",
    "    lc_array = lc_array.where((lc_array.x >= lc_stack.x[(i - 1) * config[\"chips\"][\"sample_size\"]]) &\n",
    "                              (lc_array.x < lc_stack.x[i * config[\"chips\"][\"sample_size\"]]) & \n",
    "                              (lc_array.y <= lc_stack.y[(j - 1) * config[\"chips\"][\"sample_size\"]] ) &\n",
    "                              (lc_array.y > lc_stack.y[j * config[\"chips\"][\"sample_size\"]])\n",
    "                             )\n",
    "    \n",
    "\n",
    "    lc_array = lc_array.fillna(-99)\n",
    "    lc_array = lc_array.rio.write_nodata(-99)\n",
    "    lc_array = lc_array.astype(np.dtype(np.int8))\n",
    "    lc_array = lc_array.rename(\"lc\")\n",
    "    break\n",
    "#     gen_status = gen_chips(s2_array, lc_array, global_index)\n",
    "#     if gen_status:\n",
    "#         metadata_df = pd.concat([pd.DataFrame([[global_index,\n",
    "#                                                 lc_array.mean(skipna=True).compute().data,\n",
    "#                                                 s2_stack.x[i].data,\n",
    "#                                                 s2_stack.y[j].data,\n",
    "#                                                 s2_items[0].properties[\"proj:epsg\"]]\n",
    "#                                               ],\n",
    "#                                               columns=metadata_df.columns\n",
    "#                                              ),\n",
    "#                                  metadata_df],\n",
    "#                                 ignore_index=True\n",
    "#                                )\n",
    "#                     global_index += 1\n",
    "# metadata_df.to_csv('/home/benchuser/data/metadata_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2e363-ee93-4d83-bc9b-d77b30b391ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "lc_path = f\"/home/benchuser/data/lc_{index:05}.tif\"\n",
    "for dt in s2_array.time.values:\n",
    "    ts = pd.to_datetime(str(dt)) \n",
    "    s2_path = f\"/home/benchuser/data/s2_{index:05}_{ts.strftime('%Y%m%d')}.tif\"\n",
    "    s2_array.sel(time = dt).squeeze().rio.to_raster(s2_path)\n",
    "\n",
    "lc_array.rio.to_raster(lc_path)\n",
    "gen_status = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e49aa-dcfb-4618-9efe-66691eadedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(s2_items) == 0:\n",
    "#     continue\n",
    "# metadata_df = pd.DataFrame(columns=[\"chip_id\", \"lc\", \"tlc_x\", \"tlc_y\", \"epsg\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
