{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5f12a-bb8e-4846-b696-1bd19f31c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e11f5-544d-414b-92ea-26baa6cb2cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "import pystac\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3 import Retry\n",
    "from pystac_client.stac_api_io import StacApiIO\n",
    "import planetary_computer\n",
    "\n",
    "import dask.distributed\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from src.utils import search_s2_scenes, search_lc_scene, stack_s2_data, stack_lc_data, unique_class, missing_values, gen_chips\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546b8a0-5699-4a1c-8d08-1fa525b08ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import rasterio\n",
    "import stackstac \n",
    "from src.utils import mask_cloudy_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60adf776-6de5-4c7b-9ca7-5a47c044e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from rasterio.features import rasterize\n",
    "from shapely.geometry import mapping\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage import uniform_filter\n",
    "from shapely.geometry import shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4de254-75ae-4e58-ae3e-422ff6a4f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5305e5b8-812e-4fde-80cd-3d51cc3979ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3988ac7-764b-4f5f-af05-f70d2a12a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_gdf = gpd.read_file(\"data/mtbs/mtbs_perims_DD.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aaba99-935b-41ed-8d6c-d53a4bd2ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_date(event_id):\n",
    "    start_date = pd.to_datetime(event_id[-8:], format=\"%Y%m%d\")\n",
    "    return start_date\n",
    "\n",
    "def add_pre_date(pre_id):\n",
    "    if len(pre_id)<=15:\n",
    "        pre_date = pd.to_datetime(pre_id[-8:], format=\"%Y%m%d\")\n",
    "    else:\n",
    "        pre_date = pd.to_datetime(pre_id.split(\"_\")[0][-8:], format=\"%Y%m%d\")\n",
    "\n",
    "    return pre_date\n",
    "\n",
    "def add_post_date(post_id):\n",
    "    if len(post_id)<=15:\n",
    "        post_date = pd.to_datetime(post_id[-8:], format=\"%Y%m%d\")\n",
    "    else:\n",
    "        post_date = pd.to_datetime(post_id.split(\"_\")[0][-8:], format=\"%Y%m%d\")\n",
    "\n",
    "    return post_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dbd209-1490-4319-aca8-dd06b05e666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_gdf[\"start_date\"] = aoi_gdf[\"Event_ID\"].apply(add_start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19acc4fc-dafb-4ca3-abd8-c254b1342c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fires = aoi_gdf\n",
    "selected_fires = selected_fires[selected_fires[\"Incid_Type\"].isin([\"Wildfire\"])] #, \"Prescribed Fire\"\n",
    "selected_fires = selected_fires[selected_fires[\"Comment\"].isnull()]\n",
    "selected_fires = selected_fires[~selected_fires[\"Pre_ID\"].isnull()]\n",
    "selected_fires = selected_fires[~selected_fires[\"Post_ID\"].isnull()]\n",
    "selected_fires = selected_fires[selected_fires[\"start_date\"]>pd.to_datetime(\"20230101\", format=\"%Y%m%d\")]\n",
    "# selected_fires = selected_fires[selected_fires[\"start_date\"]<pd.to_datetime(\"20240101\", format=\"%Y%m%d\")]\n",
    "len(selected_fires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa8208-2c57-457d-b1b9-f3cb8117397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fires[\"pre_date\"] = selected_fires[\"Pre_ID\"].apply(add_pre_date)\n",
    "selected_fires[\"post_date\"] = selected_fires[\"Post_ID\"].apply(add_post_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e8dae-3733-4d16-bc15-e6f7214f7de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()#(n_workers=8, threads_per_worker=2)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b90881-1023-49bd-89bd-9f764872f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry = Retry(\n",
    "    total=10, backoff_factor=1, status_forcelist=[502, 503, 504], allowed_methods=None\n",
    ")\n",
    "stac_api_io = StacApiIO(max_retries=retry)\n",
    "\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    "    stac_io=stac_api_io\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d531bbc1-f8ba-40b3-b748-0c8d739cda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_df = pd.DataFrame(columns=[\"chip_id\", \"date\", \"sample_id\", \"type\", \"x_center\", \"y_center\", \"epsg\"])\n",
    "metadata_df = pd.read_csv(\"../fire_data/metadata_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87359616-18ae-4d85-b4f9-25a75dfe7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_ranges(row):\n",
    "    pre_start_date = row[\"start_date\"]-timedelta(days=91)\n",
    "    pre_end_date = row[\"start_date\"]-timedelta(days=1)\n",
    "\n",
    "    post_start_date = row[\"post_date\"]+timedelta(days=1)\n",
    "    post_end_date = row[\"post_date\"]+timedelta(days=91)\n",
    "\n",
    "    pre_dates = f\"{str(pre_start_date).split(\" \")[0]}/{str(pre_end_date).split(\" \")[0]}\"\n",
    "    post_dates = f\"{str(post_start_date).split(\" \")[0]}/{str(post_end_date).split(\" \")[0]}\"\n",
    "\n",
    "    control_dates = []\n",
    "    for delta_year in range(1, 8):\n",
    "        control_start_date = pre_start_date-timedelta(days=delta_year*365)\n",
    "        control_end_date = pre_end_date-timedelta(days=delta_year*365)\n",
    "        control_date = f\"{str(control_start_date).split(\" \")[0]}/{str(control_end_date).split(\" \")[0]}\"\n",
    "        control_dates.append([control_date])\n",
    "    \n",
    "    return [pre_dates, post_dates], control_dates\n",
    "\n",
    "def rasterize_aoi(aoi, s2_stack):\n",
    "    \"\"\"\n",
    "    Rasterize the AOI polygon into a burn mask\n",
    "    \"\"\"\n",
    "\n",
    "    aoi_gdf = gpd.GeoDataFrame(\n",
    "        {\"geometry\": [shape(aoi['geometry'])]},\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    aoi_proj = aoi_gdf.to_crs(s2_stack.rio.crs)\n",
    "    \n",
    "    burn_mask = rasterize(\n",
    "        [(mapping(aoi_proj['geometry'].iloc[0]), 1)],\n",
    "        out_shape=(s2_stack.sizes['y'], s2_stack.sizes['x']),\n",
    "        transform=s2_stack.rio.transform(),\n",
    "        fill=0,\n",
    "        dtype='uint8'\n",
    "    )\n",
    "    \n",
    "    burn_mask_da = xr.DataArray(\n",
    "        burn_mask,\n",
    "        coords={\"y\": s2_stack[\"y\"], \"x\": s2_stack[\"x\"]},\n",
    "        dims=(\"y\", \"x\")\n",
    "    )\n",
    "\n",
    "    return burn_mask_da\n",
    "\n",
    "def crop_burn_window(s2_stack, burn_mask, config):\n",
    "    \n",
    "    window_size = config['chips']['chip_size']\n",
    "\n",
    "    # Apply uniform filter (mean filter), then scale to get sum\n",
    "    burn_mean = uniform_filter(burn_mask.values.astype(float), size=window_size, mode='constant', cval=0.0)\n",
    "    burn_sum = burn_mean * (window_size ** 2)\n",
    "    \n",
    "    # Find maximum sum\n",
    "    max_idx = np.unravel_index(np.argmax(burn_sum), burn_sum.shape)\n",
    "    y_idx, x_idx = max_idx\n",
    "    \n",
    "    # Calculate start indices\n",
    "    y_start = max(y_idx - window_size // 2, 0)\n",
    "    x_start = max(x_idx - window_size // 2, 0)\n",
    "        \n",
    "    cropped_stack = s2_stack.isel(\n",
    "        y=slice(y_start, y_start + window_size),\n",
    "        x=slice(x_start, x_start + window_size)\n",
    "    )\n",
    "    \n",
    "    return cropped_stack\n",
    "\n",
    "def harmonize_to_old(data):\n",
    "    \"\"\"\n",
    "    Harmonize new Sentinel-2 data to the old baseline.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: xarray.DataArray\n",
    "        A DataArray with four dimensions: time, band, y, x\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    harmonized: xarray.DataArray\n",
    "        A DataArray with all values harmonized to the old\n",
    "        processing baseline.\n",
    "    \"\"\"\n",
    "    cutoff = datetime(2022, 1, 25)\n",
    "    offset = 1000\n",
    "    bands = [\n",
    "        \"B01\",\n",
    "        \"B02\",\n",
    "        \"B03\",\n",
    "        \"B04\",\n",
    "        \"B05\",\n",
    "        \"B06\",\n",
    "        \"B07\",\n",
    "        \"B08\",\n",
    "        \"B8A\",\n",
    "        \"B09\",\n",
    "        \"B10\",\n",
    "        \"B11\",\n",
    "        \"B12\",\n",
    "    ]\n",
    "\n",
    "    old = data.sel(time=slice(cutoff))\n",
    "\n",
    "    to_process = list(set(bands) & set(data.band.data.tolist()))\n",
    "    new = data.sel(time=slice(cutoff, None)).drop_sel(band=to_process)\n",
    "\n",
    "    new_harmonized = data.sel(time=slice(cutoff, None), band=to_process).clip(offset)\n",
    "    new_harmonized -= offset\n",
    "\n",
    "    new = xr.concat([new, new_harmonized], \"band\").sel(band=data.band.data.tolist())\n",
    "    \n",
    "    return xr.concat([old, new], dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7c73e-68a1-47c8-86e9-9a606efe9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fire_chips(s2_stack, aoi, config, time_series_type, epsg, index, metadata_df):\n",
    "   \n",
    "\n",
    "    try:\n",
    "        s2_stack = s2_stack.compute()\n",
    "    except:\n",
    "        print(\"skipping the AOI for no S2 data\")\n",
    "\n",
    "    \n",
    "    burn_mask = rasterize_aoi(aoi, s2_stack)\n",
    "\n",
    "    try:\n",
    "        s2_stack_cropped = crop_burn_window(s2_stack, burn_mask, config)\n",
    "    except:\n",
    "        print(\"Cropping S2 stack failed; skipping AOI\")\n",
    "    \n",
    "    if s2_stack_cropped.shape[2] != 224 or s2_stack_cropped.shape[3] != 224:\n",
    "        print(f\"Skipping chip ID {index} for mismatch dimensions\")\n",
    "        \n",
    "        return False, metadata_df \n",
    "    \n",
    "    \n",
    "    if missing_values(s2_stack_cropped, config['chips']['chip_size'], config['chips']['chip_size']):\n",
    "        print(f\"Skipping chip ID {index} for missing values\")\n",
    "        return False, metadata_df      \n",
    "    \n",
    "    s2_stack_cropped = harmonize_to_old(s2_stack_cropped)\n",
    "    \n",
    "    s2_stack_cropped = s2_stack_cropped.fillna(-999)\n",
    "    s2_stack_cropped = s2_stack_cropped.rio.write_nodata(-999)\n",
    "    s2_stack_cropped = s2_stack_cropped.astype(np.dtype(np.int16))\n",
    "    s2_stack_cropped = s2_stack_cropped.rename(\"s2\")\n",
    "\n",
    "    if time_series_type == \"event\":\n",
    "        for dt in s2_stack_cropped.time.values:\n",
    "            ts = pd.to_datetime(str(dt)) \n",
    "            s2_path = f\"/home/benchuser/fire_data/s2_{index:06}_e_{ts.strftime('%Y%m%d')}.tif\"\n",
    "            s2_stack_cropped.sel(time = dt).squeeze().rio.to_raster(s2_path)\n",
    "\n",
    "            metadata_df = pd.concat([pd.DataFrame([[index,\n",
    "                                                    ts.strftime('%Y%m%d'),\n",
    "                                                    f\"{index:06}_e_{ts.strftime('%Y%m%d')}\",\n",
    "                                                    \"event\",\n",
    "                                                    s2_stack_cropped.x[int(len(s2_stack_cropped.x)/2)].data,\n",
    "                                                    s2_stack_cropped.y[int(len(s2_stack_cropped.y)/2)].data,\n",
    "                                                    epsg]\n",
    "                                                  ],\n",
    "                                                  columns=metadata_df.columns\n",
    "                                                 ),\n",
    "                                     metadata_df],\n",
    "                                    ignore_index=True\n",
    "                                   )\n",
    "            \n",
    "    else:\n",
    "        dt = s2_stack_cropped.time.values[0]\n",
    "        ts = pd.to_datetime(str(dt)) \n",
    "        s2_path = f\"/home/benchuser/fire_data/s2_{index:06}_c_{ts.strftime('%Y%m%d')}.tif\"\n",
    "        s2_stack_cropped.sel(time = dt).squeeze().rio.to_raster(s2_path)\n",
    "        metadata_df = pd.concat([pd.DataFrame([[index,\n",
    "                                                ts.strftime('%Y%m%d'),\n",
    "                                                f\"{index:06}_c_{ts.strftime('%Y%m%d')}\",\n",
    "                                                \"control\",\n",
    "                                                s2_stack_cropped.x[int(len(s2_stack_cropped.x)/2)].data,\n",
    "                                                s2_stack_cropped.y[int(len(s2_stack_cropped.y)/2)].data,\n",
    "                                                epsg]\n",
    "                                              ],\n",
    "                                      columns=metadata_df.columns\n",
    "                                     ),\n",
    "                         metadata_df],\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "\n",
    "    return True, metadata_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba44339-dadb-45bd-869c-6ee257adc785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, aoi in selected_fires[106:].iterrows():\n",
    "    print(f\"\\nProcessing AOI at index {index}\")\n",
    "    \n",
    "    aoi_bounds = aoi['geometry'].bounds\n",
    "    s2_items = pystac.item_collection.ItemCollection([])\n",
    "    event_date_ranges, control_date_ranges = get_date_ranges(aoi)\n",
    "    for date_range in event_date_ranges:        \n",
    "        s2_items_season = search_s2_scenes(aoi, date_range, catalog, config)\n",
    "        s2_items += s2_items_season\n",
    "\n",
    "    if len(s2_items)<2:\n",
    "        print(f\"Missing Sentinel-2 scenes for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "        \n",
    "\n",
    "    s2_stack = stack_s2_data(s2_items, config)\n",
    "    if s2_stack is None:\n",
    "        print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        epsg = s2_items[0].properties[\"proj:epsg\"]\n",
    "    except:\n",
    "        epsg = int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])\n",
    "\n",
    "    clipping_geom = aoi[\"geometry\"]\n",
    "\n",
    "    try:\n",
    "        s2_stack = stackstac.stack(\n",
    "            s2_items,\n",
    "            assets=config[\"sentinel_2\"][\"bands\"],\n",
    "            epsg=epsg,\n",
    "            resolution=config[\"sentinel_2\"][\"resolution\"],\n",
    "            fill_value=np.nan,\n",
    "            bounds_latlon = clipping_geom.bounds\n",
    "        )\n",
    "        s2_stack = mask_cloudy_pixels(s2_stack)\n",
    "        s2_stack = s2_stack.drop_sel(band=\"SCL\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error stacking Sentinel-2 data: {e}. Skipping AOI {index}\")\n",
    "        continue\n",
    "\n",
    "    event_status, metadata_df = generate_fire_chips(s2_stack, aoi, config, \"event\", epsg, index, metadata_df)\n",
    "    if event_status:\n",
    "        for control_date_range in control_date_ranges:\n",
    "            s2_items = search_s2_scenes(aoi, control_date_range[0], catalog, config)\n",
    "            \n",
    "            if len(s2_items)<1:\n",
    "                print(f\"Missing Sentinel-2 scenes for AOI {aoi_bounds}\")\n",
    "                continue\n",
    "                \n",
    "        \n",
    "            s2_stack = stack_s2_data(s2_items, config)\n",
    "            if s2_stack is None:\n",
    "                print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds} in control year\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                epsg = s2_items[0].properties[\"proj:epsg\"]\n",
    "            except:\n",
    "                epsg = int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])\n",
    "            \n",
    "            try:\n",
    "                s2_stack = stackstac.stack(\n",
    "                    s2_items,\n",
    "                    assets=config[\"sentinel_2\"][\"bands\"],\n",
    "                    epsg=epsg,\n",
    "                    resolution=config[\"sentinel_2\"][\"resolution\"],\n",
    "                    fill_value=np.nan,\n",
    "                    bounds_latlon = clipping_geom.bounds\n",
    "                )\n",
    "                s2_stack = mask_cloudy_pixels(s2_stack)\n",
    "                s2_stack = s2_stack.drop_sel(band=\"SCL\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error stacking Sentinel-2 data: {e}. Skipping AOI {index}\")\n",
    "                continue\n",
    "        \n",
    "            control_status, metadata_df = generate_fire_chips(s2_stack, aoi, config, \"control\", epsg, index, metadata_df)\n",
    "            \n",
    "    metadata_df.to_csv('/home/benchuser/fire_data/metadata_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c4817b-7c74-4c4b-9db7-29fc3efeea2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b4ae6-d5e2-4502-a35b-e2e5c17526ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ca380-8ced-4081-83d5-e184422b74ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "folder_path = \"/home/benchuser/fire_data/\"\n",
    "\n",
    "pattern = re.compile(r\"s2_(\\w+)_(\\w+)_(\\d{8})\\.tif\")\n",
    "\n",
    "files_by_id = defaultdict(list)\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        id_ = match.group(1)\n",
    "        time_series_type = match.group(2)\n",
    "        date = match.group(3)\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        files_by_id[id_].append((date, full_path))\n",
    "\n",
    "valid_ids = [id_ for id_, files in files_by_id.items() if len(files) >= 6]\n",
    "valid_ids = sorted(valid_ids)[:6]  # Select first 10 IDs\n",
    "\n",
    "fig, axes = plt.subplots(nrows=6, ncols=6, figsize=(6, 5))\n",
    "fig.tight_layout(pad=-.8)\n",
    "\n",
    "for i, id_ in enumerate(valid_ids):\n",
    "    scenes = sorted(files_by_id[id_], key=lambda x: x[0])\n",
    "    \n",
    "    for j, (date, path) in enumerate(scenes[-6:]):\n",
    "        with rasterio.open(path) as src:\n",
    "            img = src.read([3, 2, 1]).astype(np.float32)\n",
    "\n",
    "            # img_min = img.min(axis=(1, 2), keepdims=True)\n",
    "            # img_max = img.max(axis=(1, 2), keepdims=True)\n",
    "            # img_norm = (img - img_min) / (img_max - img_min + 1e-5)\n",
    "            img_norm = img/4000\n",
    "            img_rgb = np.transpose(img_norm, (1, 2, 0))\n",
    "\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(img_rgb)\n",
    "        ax.set_title(f\"{date}\", fontsize=6)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.savefig(f\"{folder_path}/sample_fires.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e2eb3-49d3-4659-adb6-d7074564f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "folder_to_zip = f'/home/benchuser/fire_data/'\n",
    "output_zip_file = f'/home/benchuser/fire_v0.10'\n",
    "\n",
    "shutil.make_archive(output_zip_file, 'zip', folder_to_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98af2b9-0592-4b1b-a5e9-48eb3a369b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
