{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d5f12a-bb8e-4846-b696-1bd19f31c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "703e11f5-544d-414b-92ea-26baa6cb2cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "import pystac\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3 import Retry\n",
    "from pystac_client.stac_api_io import StacApiIO\n",
    "import planetary_computer\n",
    "\n",
    "import dask.distributed\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from src.utils import search_s2_scenes, search_lc_scene, stack_s2_data, stack_lc_data, unique_class, missing_values, gen_chips\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8546b8a0-5699-4a1c-8d08-1fa525b08ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import rasterio\n",
    "import stackstac \n",
    "from src.utils import mask_cloudy_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60adf776-6de5-4c7b-9ca7-5a47c044e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from rasterio.features import rasterize\n",
    "from shapely.geometry import mapping\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage import uniform_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4de254-75ae-4e58-ae3e-422ff6a4f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5305e5b8-812e-4fde-80cd-3d51cc3979ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3988ac7-764b-4f5f-af05-f70d2a12a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_gdf = gpd.read_file(\"data/mtbs/mtbs_perims_DD.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25aaba99-935b-41ed-8d6c-d53a4bd2ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_date(event_id):\n",
    "    start_date = pd.to_datetime(event_id[-8:], format=\"%Y%m%d\")\n",
    "    return start_date\n",
    "\n",
    "def add_pre_date(pre_id):\n",
    "    if len(pre_id)<=15:\n",
    "        pre_date = pd.to_datetime(pre_id[-8:], format=\"%Y%m%d\")\n",
    "    else:\n",
    "        pre_date = pd.to_datetime(pre_id.split(\"_\")[0][-8:], format=\"%Y%m%d\")\n",
    "\n",
    "    return pre_date\n",
    "\n",
    "def add_post_date(post_id):\n",
    "    if len(post_id)<=15:\n",
    "        post_date = pd.to_datetime(post_id[-8:], format=\"%Y%m%d\")\n",
    "    else:\n",
    "        post_date = pd.to_datetime(post_id.split(\"_\")[0][-8:], format=\"%Y%m%d\")\n",
    "\n",
    "    return post_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3dbd209-1490-4319-aca8-dd06b05e666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_gdf[\"start_date\"] = aoi_gdf[\"Event_ID\"].apply(add_start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19acc4fc-dafb-4ca3-abd8-c254b1342c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_fires = aoi_gdf\n",
    "selected_fires = selected_fires[selected_fires[\"Incid_Type\"].isin([\"Wildfire\"])] #, \"Prescribed Fire\"\n",
    "selected_fires = selected_fires[selected_fires[\"Comment\"].isnull()]\n",
    "selected_fires = selected_fires[~selected_fires[\"Pre_ID\"].isnull()]\n",
    "selected_fires = selected_fires[~selected_fires[\"Post_ID\"].isnull()]\n",
    "selected_fires = selected_fires[selected_fires[\"start_date\"]>pd.to_datetime(\"20230101\", format=\"%Y%m%d\")]\n",
    "# selected_fires = selected_fires[selected_fires[\"start_date\"]<pd.to_datetime(\"20240101\", format=\"%Y%m%d\")]\n",
    "len(selected_fires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45aa8208-2c57-457d-b1b9-f3cb8117397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fires[\"pre_date\"] = selected_fires[\"Pre_ID\"].apply(add_pre_date)\n",
    "selected_fires[\"post_date\"] = selected_fires[\"Post_ID\"].apply(add_post_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348e8dae-3733-4d16-bc15-e6f7214f7de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()#(n_workers=8, threads_per_worker=2)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0b90881-1023-49bd-89bd-9f764872f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry = Retry(\n",
    "    total=10, backoff_factor=1, status_forcelist=[502, 503, 504], allowed_methods=None\n",
    ")\n",
    "stac_api_io = StacApiIO(max_retries=retry)\n",
    "\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    "    stac_io=stac_api_io\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d531bbc1-f8ba-40b3-b748-0c8d739cda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.DataFrame(columns=[\"chip_id\", \"date\", \"sample_id\", \"type\", \"x_center\", \"y_center\", \"epsg\"])\n",
    "# metadata_df = pd.read_csv(\"../data/metadata_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87359616-18ae-4d85-b4f9-25a75dfe7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_ranges(row):\n",
    "    pre_start_date = row[\"start_date\"]-timedelta(days=91)\n",
    "    pre_end_date = row[\"start_date\"]-timedelta(days=1)\n",
    "\n",
    "    post_start_date = row[\"post_date\"]+timedelta(days=1)\n",
    "    post_end_date = row[\"post_date\"]+timedelta(days=91)\n",
    "\n",
    "    pre_dates = f\"{str(pre_start_date).split(\" \")[0]}/{str(pre_end_date).split(\" \")[0]}\"\n",
    "    post_dates = f\"{str(post_start_date).split(\" \")[0]}/{str(post_end_date).split(\" \")[0]}\"\n",
    "\n",
    "    control_dates = []\n",
    "    for delta_year in range(1, 8):\n",
    "        control_start_date = pre_start_date-timedelta(days=delta_year*365)\n",
    "        control_end_date = pre_end_date-timedelta(days=delta_year*365)\n",
    "        control_date = f\"{str(control_start_date).split(\" \")[0]}/{str(control_end_date).split(\" \")[0]}\"\n",
    "        control_dates.append([control_date])\n",
    "    \n",
    "    return [pre_dates, post_dates], control_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45f7c73e-68a1-47c8-86e9-9a606efe9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fire_chips(s2_stack, config, time_series_type, epsg, index, metadata_df):\n",
    "    x_i = int((len(s2_stack.x) - config['chips']['chip_size'])/2)\n",
    "    y_i = int((len(s2_stack.y) - config['chips']['chip_size'])/2)\n",
    "    \n",
    "    s2_stack = s2_stack.isel(x = slice(x_i, x_i + config['chips']['chip_size']), y = slice(y_i, y_i + config['chips']['chip_size']))\n",
    "\n",
    "    if s2_stack.shape[2] != 224 or s2_stack.shape[3] != 224:\n",
    "        print(f\"Skipping chip ID {index} for mismatch dimensions\")\n",
    "        return False, metadata_df \n",
    "    \n",
    "    try:\n",
    "        s2_stack = s2_stack.compute()\n",
    "    except:\n",
    "        print(\"skipping the AOI for no S2 data\")\n",
    "\n",
    "    if missing_values(s2_stack, config['chips']['chip_size'], config['chips']['sample_size']):\n",
    "        print(f\"Skipping chip ID {index} for missing values\")\n",
    "        return False, metadata_df      \n",
    "    \n",
    "    s2_stack = s2_stack.fillna(-999)\n",
    "    s2_stack = s2_stack.rio.write_nodata(-999)\n",
    "    s2_stack = s2_stack.astype(np.dtype(np.int16))\n",
    "    s2_stack = s2_stack.rename(\"s2\")\n",
    "\n",
    "    if time_series_type == \"event\":\n",
    "        for dt in s2_stack.time.values:\n",
    "            ts = pd.to_datetime(str(dt)) \n",
    "            s2_path = f\"/home/benchuser/fire_data/s2_{index:06}_e_{ts.strftime('%Y%m%d')}.tif\"\n",
    "            s2_stack.sel(time = dt).squeeze().rio.to_raster(s2_path)\n",
    "\n",
    "            metadata_df = pd.concat([pd.DataFrame([[index,\n",
    "                                                    ts.strftime('%Y%m%d'),\n",
    "                                                    f\"{index:06}_e_{ts.strftime('%Y%m%d')}\",\n",
    "                                                    \"event\",\n",
    "                                                    s2_stack.x[int(len(s2_stack.x)/2)].data,\n",
    "                                                    s2_stack.y[int(len(s2_stack.y)/2)].data,\n",
    "                                                    epsg]\n",
    "                                                  ],\n",
    "                                                  columns=metadata_df.columns\n",
    "                                                 ),\n",
    "                                     metadata_df],\n",
    "                                    ignore_index=True\n",
    "                                   )\n",
    "            \n",
    "    else:\n",
    "        dt = s2_stack.time.values[0]\n",
    "        ts = pd.to_datetime(str(dt)) \n",
    "        s2_path = f\"/home/benchuser/fire_data/s2_{index:06}_c_{ts.strftime('%Y%m%d')}.tif\"\n",
    "        s2_stack.sel(time = dt).squeeze().rio.to_raster(s2_path)\n",
    "        metadata_df = pd.concat([pd.DataFrame([[index,\n",
    "                                                ts.strftime('%Y%m%d'),\n",
    "                                                f\"{index:06}_c_{ts.strftime('%Y%m%d')}\",\n",
    "                                                \"control\",\n",
    "                                                s2_stack.x[int(len(s2_stack.x)/2)].data,\n",
    "                                                s2_stack.y[int(len(s2_stack.y)/2)].data,\n",
    "                                                epsg]\n",
    "                                              ],\n",
    "                                      columns=metadata_df.columns\n",
    "                                     ),\n",
    "                         metadata_df],\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "\n",
    "    return True, metadata_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ba44339-dadb-45bd-869c-6ee257adc785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing AOI at index 29590\n"
     ]
    }
   ],
   "source": [
    "for index, aoi in selected_fires.iterrows():\n",
    "    print(f\"\\nProcessing AOI at index {index}\")\n",
    "    \n",
    "    aoi_bounds = aoi['geometry'].bounds\n",
    "    s2_items = pystac.item_collection.ItemCollection([])\n",
    "    event_date_ranges, control_date_ranges = get_date_ranges(aoi)\n",
    "    for date_range in event_date_ranges:        \n",
    "        s2_items_season = search_s2_scenes(aoi, date_range, catalog, config)\n",
    "        s2_items += s2_items_season\n",
    "\n",
    "    if len(s2_items)<2:\n",
    "        print(f\"Missing Sentinel-2 scenes for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "        \n",
    "\n",
    "    s2_stack = stack_s2_data(s2_items, config)\n",
    "    if s2_stack is None:\n",
    "        print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        epsg = s2_items[0].properties[\"proj:epsg\"]\n",
    "    except:\n",
    "        epsg = int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])\n",
    "\n",
    "    clipping_geom = aoi[\"geometry\"]\n",
    "\n",
    "    try:\n",
    "        s2_stack = stackstac.stack(\n",
    "            s2_items,\n",
    "            assets=config[\"sentinel_2\"][\"bands\"],\n",
    "            epsg=epsg,\n",
    "            resolution=config[\"sentinel_2\"][\"resolution\"],\n",
    "            fill_value=np.nan,\n",
    "            bounds_latlon = clipping_geom.bounds\n",
    "        )\n",
    "        s2_stack = mask_cloudy_pixels(s2_stack)\n",
    "        s2_stack = s2_stack.drop_sel(band=\"SCL\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error stacking Sentinel-2 data: {e}. Skipping AOI {index}\")\n",
    "        continue\n",
    "\n",
    "    event_status, metadata_df = generate_fire_chips(s2_stack, config, \"event\", epsg, index, metadata_df)\n",
    "    # if event_status:\n",
    "    #     for control_date_range in control_date_ranges:\n",
    "    #         s2_items = search_s2_scenes(aoi, control_date_range[0], catalog, config)\n",
    "            \n",
    "    #         if len(s2_items)<1:\n",
    "    #             print(f\"Missing Sentinel-2 scenes for AOI {aoi_bounds}\")\n",
    "    #             continue\n",
    "                \n",
    "        \n",
    "    #         s2_stack = stack_s2_data(s2_items, config)\n",
    "    #         if s2_stack is None:\n",
    "    #             print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds} in control year\")\n",
    "    #             continue\n",
    "                \n",
    "    #         try:\n",
    "    #             epsg = s2_items[0].properties[\"proj:epsg\"]\n",
    "    #         except:\n",
    "    #             epsg = int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])\n",
    "            \n",
    "    #         try:\n",
    "    #             s2_stack = stackstac.stack(\n",
    "    #                 s2_items,\n",
    "    #                 assets=config[\"sentinel_2\"][\"bands\"],\n",
    "    #                 epsg=epsg,\n",
    "    #                 resolution=config[\"sentinel_2\"][\"resolution\"],\n",
    "    #                 fill_value=np.nan,\n",
    "    #                 bounds_latlon = clipping_geom.bounds\n",
    "    #             )\n",
    "    #             s2_stack = mask_cloudy_pixels(s2_stack)\n",
    "    #             s2_stack = s2_stack.drop_sel(band=\"SCL\")\n",
    "    #         except Exception as e:\n",
    "    #             print(f\"Error stacking Sentinel-2 data: {e}. Skipping AOI {index}\")\n",
    "    #             continue\n",
    "        \n",
    "    #         event_status, metadata_df = generate_fire_chips(s2_stack, config, \"control\", epsg, index, metadata_df)\n",
    "            \n",
    "    metadata_df.to_csv('/home/benchuser/fire_data/metadata_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7627c3-9dd7-42f2-b44b-f8f695a20da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ad5c4-f684-4036-812c-052e07ecb76f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ca380-8ced-4081-83d5-e184422b74ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "folder_path = \"/home/benchuser/fire_data/\"\n",
    "\n",
    "pattern = re.compile(r\"s2_(\\w+)_(\\w+)_(\\d{8})\\.tif\")\n",
    "\n",
    "files_by_id = defaultdict(list)\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        id_ = match.group(1)\n",
    "        time_series_type = match.group(2)\n",
    "        date = match.group(3)\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        files_by_id[id_].append((date, full_path))\n",
    "\n",
    "valid_ids = [id_ for id_, files in files_by_id.items() if len(files) == 9]\n",
    "valid_ids = sorted(valid_ids)[:10]  # Select first 10 IDs\n",
    "\n",
    "fig, axes = plt.subplots(nrows=10, ncols=9, figsize=(10, 18))\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "for i, id_ in enumerate(valid_ids):\n",
    "    scenes = sorted(files_by_id[id_], key=lambda x: x[0])\n",
    "    \n",
    "    for j, (date, path) in enumerate(scenes):\n",
    "        with rasterio.open(path) as src:\n",
    "            img = src.read([3, 2, 1]).astype(np.float32)\n",
    "\n",
    "            # img_min = img.min(axis=(1, 2), keepdims=True)\n",
    "            # img_max = img.max(axis=(1, 2), keepdims=True)\n",
    "            # img_norm = (img - img_min) / (img_max - img_min + 1e-5)\n",
    "            img_norm = img/4000\n",
    "            img_rgb = np.transpose(img_norm, (1, 2, 0))\n",
    "\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(img_rgb)\n",
    "        ax.set_title(f\"{date}\", fontsize=8)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.savefig(f\"{folder_path}/sample_fires.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e2eb3-49d3-4659-adb6-d7074564f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "folder_to_zip = f'/home/benchuser/fire_data/'\n",
    "output_zip_file = f'/home/benchuser/fire_v0.10'\n",
    "\n",
    "shutil.make_archive(output_zip_file, 'zip', folder_to_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98af2b9-0592-4b1b-a5e9-48eb3a369b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
