{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5f12a-bb8e-4846-b696-1bd19f31c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e11f5-544d-414b-92ea-26baa6cb2cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "import pystac\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3 import Retry\n",
    "from pystac_client.stac_api_io import StacApiIO\n",
    "import planetary_computer\n",
    "\n",
    "import dask.distributed\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from src.utils import search_s2_scenes, search_lc_scene, stack_s2_data, stack_lc_data, unique_class, missing_values, gen_chips\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4de254-75ae-4e58-ae3e-422ff6a4f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5305e5b8-812e-4fde-80cd-3d51cc3979ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3988ac7-764b-4f5f-af05-f70d2a12a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_gdf = gpd.read_file(\"data/map_v0.11.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f70bb-fdc3-4c5f-8dba-2471bffa68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following AOIs have broken scenes in the STAC catalog and should be removed\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 12]\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 25]\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 46]\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 60]\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 81]\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 153]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e8dae-3733-4d16-bc15-e6f7214f7de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()#(n_workers=8, threads_per_worker=2)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b90881-1023-49bd-89bd-9f764872f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry = Retry(\n",
    "    total=10, backoff_factor=1, status_forcelist=[502, 503, 504], allowed_methods=None\n",
    ")\n",
    "stac_api_io = StacApiIO(max_retries=retry)\n",
    "\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    "    stac_io=stac_api_io\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11988702-1648-400d-894c-796738f3028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chips(s2_stack, lc_stack, epsg, sample_size, chip_size, global_index, metadata_df):\n",
    "    \n",
    "    try:\n",
    "        lc_stack = lc_stack.compute()\n",
    "    except:\n",
    "        print(\"skipping the AOI for no LC data\")\n",
    "        return global_index, metadata_df\n",
    "    \n",
    "    lc_uniqueness = lc_stack.coarsen(x = sample_size,\n",
    "                                     y = sample_size,\n",
    "                                     boundary = \"trim\"\n",
    "                                    ).reduce(unique_class)\n",
    "    lc_uniqueness[0, :] = False\n",
    "    lc_uniqueness[-1, :] = False\n",
    "    lc_uniqueness[:, 0] = False\n",
    "    lc_uniqueness[:, -1] = False\n",
    "\n",
    "    ys, xs = np.where(lc_uniqueness)\n",
    "    print(\"Loading s2_stack\")\n",
    "    \n",
    "    try:\n",
    "        s2_stack = s2_stack.compute()\n",
    "    except:\n",
    "        print(\"skipping the AOI for no S2 data\")\n",
    "        return global_index, metadata_df\n",
    "    \n",
    "    \n",
    "    for index in range(0, len(ys)):\n",
    "        y = ys[index]\n",
    "        x = xs[index]\n",
    "    \n",
    "            \n",
    "        x_coords = slice((x) * sample_size - int((chip_size - sample_size)/2), (x + 1) * sample_size + int((chip_size - sample_size)/2))\n",
    "        y_coords = slice((y) * sample_size - int((chip_size - sample_size)/2), (y + 1) * sample_size + int((chip_size - sample_size)/2))    \n",
    "        \n",
    "        s2_array = s2_stack.isel(x = x_coords, y = y_coords)\n",
    "        s2_array.rio.write_crs(f\"epsg:{epsg}\", inplace=True)\n",
    "        s2_array = s2_array.where((s2_array.x >= s2_stack.x[(x) * sample_size]) &\n",
    "                                  (s2_array.x < s2_stack.x[(x + 1) * sample_size]) & \n",
    "                                  (s2_array.y <= s2_stack.y[(y) * sample_size]) &\n",
    "                                  (s2_array.y > s2_stack.y[(y + 1) * sample_size])\n",
    "                                 )\n",
    "        \n",
    "        if missing_values(s2_array, chip_size, sample_size):\n",
    "            continue        \n",
    "        \n",
    "        s2_array = s2_array.fillna(-999)\n",
    "        s2_array = s2_array.rio.write_nodata(-999)\n",
    "        s2_array = s2_array.astype(np.dtype(np.int16))\n",
    "        s2_array = s2_array.rename(\"s2\")\n",
    "        \n",
    "\n",
    "                \n",
    "        lc_array = lc_stack.isel(x = x_coords, y = y_coords)\n",
    "        lc_array.rio.write_crs(f\"epsg:{epsg}\", inplace=True)\n",
    "        lc_array = lc_array.where((lc_array.x >= lc_stack.x[(x) * sample_size]) &\n",
    "                                  (lc_array.x < lc_stack.x[(x + 1) * sample_size]) & \n",
    "                                  (lc_array.y <= lc_stack.y[(y) * sample_size] ) &\n",
    "                                  (lc_array.y > lc_stack.y[(y + 1) * sample_size])\n",
    "                                 )\n",
    "        \n",
    "        if missing_values(lc_array, chip_size, sample_size):\n",
    "            continue\n",
    "\n",
    "        if (np.isin(lc_array, [255, 130, 133])).any():\n",
    "            raise ValueError('Wrong LC value')\n",
    "        \n",
    "        lc_array = lc_array.fillna(0)\n",
    "        lc_array = lc_array.rio.write_nodata(0)\n",
    "        lc_array = lc_array.astype(np.dtype(np.int8))\n",
    "        lc_array = lc_array.rename(\"lc\")\n",
    "        if (np.isin(lc_array, [7])).any():\n",
    "            gen_status, dts = gen_chips(s2_array, lc_array, global_index)\n",
    "            if gen_status:\n",
    "                metadata_df = pd.concat([pd.DataFrame([[global_index,\n",
    "                                                        dts,\n",
    "                                                        np.unique(lc_array)[1],\n",
    "                                                        s2_stack.x[(x) * sample_size + int(sample_size / 2)].data,\n",
    "                                                        s2_stack.y[(y) * sample_size + int(sample_size / 2)].data,\n",
    "                                                        epsg]\n",
    "                                                      ],\n",
    "                                                      columns=metadata_df.columns\n",
    "                                                     ),\n",
    "                                         metadata_df],\n",
    "                                        ignore_index=True\n",
    "                                       )\n",
    "                global_index += 1\n",
    "    \n",
    "    return global_index, metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d531bbc1-f8ba-40b3-b748-0c8d739cda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_index = 0\n",
    "metadata_df = pd.DataFrame(columns=[\"chip_id\", \"dates\", \"lc\", \"x_center\", \"y_center\", \"epsg\"])\n",
    "# metadata_df = pd.read_csv(\"../data/metadata_df.csv\") # Use this line to continue from a previous iteration if the code stops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae971c5-2245-4ac9-88c6-a65e4d453427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, aoi in aoi_gdf[219:].iterrows():\n",
    "    print(f\"\\nProcessing AOI at index {index}\")\n",
    "    \n",
    "    aoi_bounds = aoi['geometry'].bounds\n",
    "    s2_items = pystac.item_collection.ItemCollection([])\n",
    "    for date_range in config[\"sentinel_2\"][\"time_ranges\"]:        \n",
    "        s2_items_season = search_s2_scenes(aoi, date_range, catalog, config)\n",
    "        s2_items += s2_items_season\n",
    "\n",
    "    if len(s2_items)<4:\n",
    "        print(f\"Missing Sentinel-2 scenes for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "        \n",
    "\n",
    "    s2_stack = stack_s2_data(s2_items, config)\n",
    "    if s2_stack is None:\n",
    "        print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        epsg = s2_items[0].properties[\"proj:epsg\"]\n",
    "    except:\n",
    "        epsg = int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])\n",
    "        \n",
    "\n",
    "\n",
    "    lc_items = search_lc_scene(s2_items[0].bbox, catalog, config)\n",
    "    if not lc_items:\n",
    "        print(f\"No Land Cover data found for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "    \n",
    "    lc_stack = stack_lc_data(lc_items, s2_stack.rio.crs.to_epsg(), s2_items[0].bbox, config)\n",
    "    if lc_stack is None:\n",
    "        print(f\"Failed to stack Land Cover data for AOI {aoi_bounds} and date range {date_range}\")\n",
    "        continue\n",
    "\n",
    "    global_index, metadata_df = process_chips(s2_stack,\n",
    "                                              lc_stack,\n",
    "                                              epsg,\n",
    "                                              config[\"chips\"][\"sample_size\"],\n",
    "                                              config[\"chips\"][\"chip_size\"],\n",
    "                                              global_index,\n",
    "                                              metadata_df)\n",
    "    metadata_df.to_csv('/home/benchuser/data/metadata_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc305330-bba0-488b-b94a-8565b41933a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
