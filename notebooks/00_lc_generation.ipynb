{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001daeba-0919-4d6d-b200-ec257318c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d5f12a-bb8e-4846-b696-1bd19f31c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703e11f5-544d-414b-92ea-26baa6cb2cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "import pystac\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3 import Retry\n",
    "from pystac_client.stac_api_io import StacApiIO\n",
    "import planetary_computer\n",
    "\n",
    "import dask.distributed\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from src.utils import search_s2_scenes, search_s1_scenes, search_lc_scene, stack_s2_data, stack_lc_data, unique_class, missing_values, gen_chips\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4de254-75ae-4e58-ae3e-422ff6a4f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5305e5b8-812e-4fde-80cd-3d51cc3979ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3988ac7-764b-4f5f-af05-f70d2a12a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_gdf = gpd.read_file(\"data/map_v0.30.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c4f70bb-fdc3-4c5f-8dba-2471bffa68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following AOIs have broken scenes in the STAC catalog and should be removed\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 12]\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 25]\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 46]\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 60]\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 81]\n",
    "aoi_gdf = aoi_gdf[aoi_gdf.index != 153]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348e8dae-3733-4d16-bc15-e6f7214f7de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()#(n_workers=8, threads_per_worker=2)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0b90881-1023-49bd-89bd-9f764872f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry = Retry(\n",
    "    total=10, backoff_factor=1, status_forcelist=[502, 503, 504], allowed_methods=None\n",
    ")\n",
    "stac_api_io = StacApiIO(max_retries=retry)\n",
    "\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    "    stac_io=stac_api_io\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff7832-4719-40d6-97c1-479ab1b28ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11988702-1648-400d-894c-796738f3028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chips(s2_stack, lc_stack, epsg, sample_size, chip_size, global_index, metadata_df):\n",
    "    \n",
    "    try:\n",
    "        lc_stack = lc_stack.compute()\n",
    "    except:\n",
    "        print(\"skipping the AOI for no LC data\")\n",
    "        return global_index, metadata_df\n",
    "    \n",
    "    lc_uniqueness = lc_stack.coarsen(x = sample_size,\n",
    "                                     y = sample_size,\n",
    "                                     boundary = \"trim\"\n",
    "                                    ).reduce(unique_class)\n",
    "    lc_uniqueness[0:2, :] = False\n",
    "    lc_uniqueness[-2:, :] = False\n",
    "    lc_uniqueness[:, 0:2] = False\n",
    "    lc_uniqueness[:, -2:] = False\n",
    "\n",
    "    ys, xs = np.where(lc_uniqueness)\n",
    "    print(\"Loading s2_stack\")\n",
    "    \n",
    "    try:\n",
    "        s2_stack = s2_stack.compute()\n",
    "    except:\n",
    "        print(\"skipping the AOI for no S2 data\")\n",
    "        return global_index, metadata_df\n",
    "\n",
    "    # Following indices are added to limit the number of rangeland, bareground, and water chips per tile\n",
    "    rangeland_index = 0\n",
    "    bareground_index = 0\n",
    "    water_index = 0\n",
    "    tree_index = 0\n",
    "    crops_index = 0\n",
    "    for index in range(0, len(ys)):\n",
    "        y = ys[index]\n",
    "        x = xs[index]\n",
    "    \n",
    "            \n",
    "        x_coords = slice((x) * sample_size - int((chip_size - sample_size)/2), (x + 1) * sample_size + int((chip_size - sample_size)/2))\n",
    "        y_coords = slice((y) * sample_size - int((chip_size - sample_size)/2), (y + 1) * sample_size + int((chip_size - sample_size)/2))    \n",
    "        \n",
    "        s2_array = s2_stack.isel(x = x_coords, y = y_coords)\n",
    "        s2_array.rio.write_crs(f\"epsg:{epsg}\", inplace=True)\n",
    "        s2_array = s2_array.where((s2_array.x >= s2_stack.x[(x) * sample_size]) &\n",
    "                                  (s2_array.x < s2_stack.x[(x + 1) * sample_size]) & \n",
    "                                  (s2_array.y <= s2_stack.y[(y) * sample_size]) &\n",
    "                                  (s2_array.y > s2_stack.y[(y + 1) * sample_size])\n",
    "                                 )\n",
    "        \n",
    "        if missing_values(s2_array, chip_size, sample_size):\n",
    "            continue        \n",
    "        \n",
    "        s2_array = s2_array.fillna(-999)\n",
    "        s2_array = s2_array.rio.write_nodata(-999)\n",
    "        s2_array = s2_array.astype(np.dtype(np.int16))\n",
    "        s2_array = s2_array.rename(\"s2\")\n",
    "        \n",
    "\n",
    "                \n",
    "        lc_array = lc_stack.isel(x = x_coords, y = y_coords)\n",
    "        lc_array.rio.write_crs(f\"epsg:{epsg}\", inplace=True)\n",
    "        lc_array = lc_array.where((lc_array.x >= lc_stack.x[(x) * sample_size]) &\n",
    "                                  (lc_array.x < lc_stack.x[(x + 1) * sample_size]) & \n",
    "                                  (lc_array.y <= lc_stack.y[(y) * sample_size] ) &\n",
    "                                  (lc_array.y > lc_stack.y[(y + 1) * sample_size])\n",
    "                                 )\n",
    "        \n",
    "        if missing_values(lc_array, chip_size, sample_size):\n",
    "            continue\n",
    "\n",
    "        if (np.isin(lc_array, [255, 130, 133])).any():\n",
    "            raise ValueError('Wrong LC value')\n",
    "        \n",
    "        # Skipping Flooded Vegetation\n",
    "        if (np.isin(lc_array, [4])).any():\n",
    "            continue\n",
    "        lc_array = lc_array.fillna(0)\n",
    "        lc_array = lc_array.rio.write_nodata(0)\n",
    "        lc_array = lc_array.astype(np.dtype(np.int8))\n",
    "        lc_array = lc_array.rename(\"lc\")\n",
    "\n",
    "        \n",
    "        lc = np.unique(lc_array)\n",
    "        if lc[1] == 1:\n",
    "            water_index += 1\n",
    "            if water_index > 400:\n",
    "                continue \n",
    "        elif lc[1] == 8:\n",
    "            bareground_index += 1\n",
    "            if bareground_index > 400:\n",
    "                continue\n",
    "        elif lc[1] == 11:\n",
    "            rangeland_index += 1\n",
    "            if rangeland_index > 400:\n",
    "                continue\n",
    "        elif lc[1] == 2:\n",
    "            tree_index += 1\n",
    "            if tree_index > 400:\n",
    "                continue\n",
    "        elif lc[1] == 5:\n",
    "            crops_index += 1\n",
    "            if crops_index > 400:\n",
    "                continue\n",
    "\n",
    "        gen_status, dts = gen_chips(s2_array, lc_array, global_index)\n",
    "        if gen_status:\n",
    "            metadata_df = pd.concat([pd.DataFrame([[global_index,\n",
    "                                                    dts,\n",
    "                                                    np.unique(lc_array)[1],\n",
    "                                                    s2_stack.x[(x) * sample_size + int(sample_size / 2)].data,\n",
    "                                                    s2_stack.y[(y) * sample_size + int(sample_size / 2)].data,\n",
    "                                                    epsg]\n",
    "                                                  ],\n",
    "                                                  columns=metadata_df.columns\n",
    "                                                 ),\n",
    "                                     metadata_df],\n",
    "                                    ignore_index=True\n",
    "                                   )\n",
    "            global_index += 1\n",
    "    \n",
    "    return global_index, metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d531bbc1-f8ba-40b3-b748-0c8d739cda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_index = 0\n",
    "metadata_df = pd.DataFrame(columns=[\"chip_id\", \"dates\", \"lc\", \"x_center\", \"y_center\", \"epsg\"])\n",
    "# metadata_df = pd.read_csv(\"../data/metadata_df.csv\") # Use this line to continue from a previous iteration if the code stops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ae971c5-2245-4ac9-88c6-a65e4d453427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing AOI at index 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stack_s1_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m     s1_item = search_s1_scenes(aoi, s2_datetime, catalog, config)\n\u001b[32m     31\u001b[39m     s1_items += s1_item\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m s1_stack = \u001b[43mstack_s1_data\u001b[49m(s1_items, config)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m s1_stack \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'stack_s1_data' is not defined"
     ]
    }
   ],
   "source": [
    "for index, aoi in aoi_gdf.iterrows():\n",
    "    print(f\"\\nProcessing AOI at index {index}\")\n",
    "    \n",
    "    aoi_bounds = aoi['geometry'].bounds\n",
    "    s2_items = pystac.item_collection.ItemCollection([])\n",
    "    for date_range in config[\"sentinel_2\"][\"time_ranges\"]:        \n",
    "        s2_items_season = search_s2_scenes(aoi, date_range, catalog, config)\n",
    "        s2_items += s2_items_season\n",
    "\n",
    "    if len(s2_items)<4:\n",
    "        print(f\"Missing Sentinel-2 scenes for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "        \n",
    "\n",
    "    s2_stack = stack_s2_data(s2_items, config)\n",
    "    if s2_stack is None:\n",
    "        print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        epsg = s2_items[0].properties[\"proj:epsg\"]\n",
    "    except:\n",
    "        epsg = int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])\n",
    "\n",
    "\n",
    "    s1_items = pystac.item_collection.ItemCollection([])\n",
    "\n",
    "    for s2_item in s2_items:\n",
    "        s2_datetime = s2_item.datetime\n",
    "        s1_item = search_s1_scenes(aoi, s2_datetime, catalog, config)\n",
    "        s1_items += s1_item\n",
    "\n",
    "    s1_stack = stack_s1_data(s1_items, config)\n",
    "    break\n",
    "    if s1_stack is None:\n",
    "        print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "\n",
    "    lc_items = search_lc_scene(s2_items[0].bbox, catalog, config)\n",
    "    if not lc_items:\n",
    "        print(f\"No Land Cover data found for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "    \n",
    "    lc_stack = stack_lc_data(lc_items, s2_stack.rio.crs.to_epsg(), s2_items[0].bbox, config)\n",
    "    if lc_stack is None:\n",
    "        print(f\"Failed to stack Land Cover data for AOI {aoi_bounds} and date range {date_range}\")\n",
    "        continue\n",
    "\n",
    "    global_index, metadata_df = process_chips(s2_stack,\n",
    "                                              lc_stack,\n",
    "                                              epsg,\n",
    "                                              config[\"chips\"][\"sample_size\"],\n",
    "                                              config[\"chips\"][\"chip_size\"],\n",
    "                                              global_index,\n",
    "                                              metadata_df)\n",
    "    metadata_df.to_csv('/home/benchuser/data/metadata_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62f69455-986d-46ba-a5fa-80dcc0f6a09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-18 04:16:57.544351+00:00 2023-02-18 08:50:21.024000+00:00\n",
      "2023-04-19 04:16:58.051502+00:00 2023-04-19 08:46:01.024000+00:00\n",
      "2023-07-12 04:17:03.121254+00:00 2023-07-13 08:46:49.024000+00:00\n",
      "2023-12-27 04:17:04.257535+00:00 2023-12-30 08:52:59.024000+00:00\n"
     ]
    }
   ],
   "source": [
    "for s1_item, s2_item in zip(s1_items, s2_items):\n",
    "    print(s1_item.datetime, s2_item.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8216b98-d25a-4cb2-b3b2-f5f4d7878d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc50aa1b-025c-45fb-8b9b-f487b4551690",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bb8d71c-b1a0-43ce-b53f-6925ec56a39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-18 08:50:21.024000+00:00\n",
      "2023-04-19 08:46:01.024000+00:00\n",
      "2023-07-13 08:46:49.024000+00:00\n",
      "2023-12-30 08:52:59.024000+00:00\n"
     ]
    }
   ],
   "source": [
    "for item in s2_items:\n",
    "    print(item.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e9dda-3348-4ea3-bb86-b5cab074b83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865788d-ecec-4600-9f57-ead3b94b7b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
