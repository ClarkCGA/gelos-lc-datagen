{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666e0ed1",
   "metadata": {},
   "source": [
    "##### Fire Generation for other areas outside of USA\n",
    "Use the // pre and post fire images // to define a \"year\" for generating time series.\n",
    "\n",
    "Then generate 4 images during that event year, and select the same range of months in previous years to sample for control years. \n",
    "\n",
    "Note: the event year should have a sample after the date of the post fire image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4988df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n",
    "import pystac_client\n",
    "import pystac\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3 import Retry\n",
    "from pystac_client.stac_api_io import StacApiIO\n",
    "import planetary_computer\n",
    "\n",
    "import dask.distributed\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from src.utils import search_s2_scenes, search_lc_scene, stack_s2_data, stack_lc_data, unique_class, missing_values, gen_chips\n",
    "import yaml\n",
    "from datetime import datetime, timedelta\n",
    "import rasterio\n",
    "import stackstac \n",
    "from src.utils import mask_cloudy_pixels\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from rasterio.features import rasterize\n",
    "from shapely.geometry import mapping\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage import uniform_filter\n",
    "from shapely.geometry import shape\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f8cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3982c95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>event_type</th>\n",
       "      <th>date</th>\n",
       "      <th>path</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Almonaster</td>\n",
       "      <td>pre</td>\n",
       "      <td>2022-07-12</td>\n",
       "      <td>/workspace/Rufai/data/S2-WCD/Almonaster/img1_c...</td>\n",
       "      <td>MULTIPOLYGON (((-1.9465144286373106 41.3722766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Almonaster</td>\n",
       "      <td>post</td>\n",
       "      <td>2022-07-27</td>\n",
       "      <td>/workspace/Rufai/data/S2-WCD/Almonaster/img2_c...</td>\n",
       "      <td>MULTIPOLYGON (((-1.9465144286373106 41.3722766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Almonaster</td>\n",
       "      <td>mask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/workspace/Rufai/data/S2-WCD/Almonaster/cm/cm.tif</td>\n",
       "      <td>MULTIPOLYGON (((-1.9465144286373106 41.3722766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Attica</td>\n",
       "      <td>pre</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>/workspace/Rufai/data/S2-WCD/Attica/img1_cropp...</td>\n",
       "      <td>MULTIPOLYGON (((-0.7064004420359428 38.0931080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Attica</td>\n",
       "      <td>post</td>\n",
       "      <td>2021-08-28</td>\n",
       "      <td>/workspace/Rufai/data/S2-WCD/Attica/img2_cropp...</td>\n",
       "      <td>MULTIPOLYGON (((-0.7064004420359428 38.0931080...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     location event_type        date  \\\n",
       "0  Almonaster        pre  2022-07-12   \n",
       "1  Almonaster       post  2022-07-27   \n",
       "2  Almonaster       mask         NaN   \n",
       "3      Attica        pre  2021-08-16   \n",
       "4      Attica       post  2021-08-28   \n",
       "\n",
       "                                                path  \\\n",
       "0  /workspace/Rufai/data/S2-WCD/Almonaster/img1_c...   \n",
       "1  /workspace/Rufai/data/S2-WCD/Almonaster/img2_c...   \n",
       "2  /workspace/Rufai/data/S2-WCD/Almonaster/cm/cm.tif   \n",
       "3  /workspace/Rufai/data/S2-WCD/Attica/img1_cropp...   \n",
       "4  /workspace/Rufai/data/S2-WCD/Attica/img2_cropp...   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((-1.9465144286373106 41.3722766...  \n",
       "1  MULTIPOLYGON (((-1.9465144286373106 41.3722766...  \n",
       "2  MULTIPOLYGON (((-1.9465144286373106 41.3722766...  \n",
       "3  MULTIPOLYGON (((-0.7064004420359428 38.0931080...  \n",
       "4  MULTIPOLYGON (((-0.7064004420359428 38.0931080...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_df = pd.read_csv(\"data/s2_wcd_fires.csv\")\n",
    "fire_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a1bae8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>geometry</th>\n",
       "      <th>pre_date</th>\n",
       "      <th>post_date</th>\n",
       "      <th>mask_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Almonaster</td>\n",
       "      <td>MULTIPOLYGON (((-1.94651 41.37228, -1.94652 41...</td>\n",
       "      <td>2022-07-12</td>\n",
       "      <td>2022-07-27</td>\n",
       "      <td>/workspace/Rufai/data/S2-WCD/Almonaster/cm/cm.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attica</td>\n",
       "      <td>MULTIPOLYGON (((-0.7064 38.09311, -0.7064 38.0...</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>2021-08-28</td>\n",
       "      <td>/workspace/Rufai/data/S2-WCD/Attica/cm/cm.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia_1</td>\n",
       "      <td>POLYGON ((-4.47264 58.56369, -4.47263 58.5636,...</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>/workspace/Rufai/data/S2-WCD/Australia_1/cm/cm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia_2</td>\n",
       "      <td>MULTIPOLYGON (((-4.49479 58.50658, -4.49513 58...</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>/workspace/Rufai/data/S2-WCD/Australia_2/cm/cm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bejis</td>\n",
       "      <td>MULTIPOLYGON (((-0.71135 39.88491, -0.71147 39...</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>/workspace/Rufai/data/S2-WCD/Bejis/cm/cm.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      location                                           geometry   pre_date  \\\n",
       "0   Almonaster  MULTIPOLYGON (((-1.94651 41.37228, -1.94652 41... 2022-07-12   \n",
       "1       Attica  MULTIPOLYGON (((-0.7064 38.09311, -0.7064 38.0... 2021-08-16   \n",
       "2  Australia_1  POLYGON ((-4.47264 58.56369, -4.47263 58.5636,... 2021-01-31   \n",
       "3  Australia_2  MULTIPOLYGON (((-4.49479 58.50658, -4.49513 58... 2021-01-31   \n",
       "4        Bejis  MULTIPOLYGON (((-0.71135 39.88491, -0.71147 39... 2022-08-08   \n",
       "\n",
       "   post_date                                          mask_path  \n",
       "0 2022-07-27  /workspace/Rufai/data/S2-WCD/Almonaster/cm/cm.tif  \n",
       "1 2021-08-28      /workspace/Rufai/data/S2-WCD/Attica/cm/cm.tif  \n",
       "2 2021-02-20  /workspace/Rufai/data/S2-WCD/Australia_1/cm/cm...  \n",
       "3 2021-02-20  /workspace/Rufai/data/S2-WCD/Australia_2/cm/cm...  \n",
       "4 2022-08-23       /workspace/Rufai/data/S2-WCD/Bejis/cm/cm.tif  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-date, post-date, geometry\n",
    "from shapely.wkt import loads\n",
    "df_filtered = fire_df[fire_df[\"event_type\"].isin([\"pre\", \"post\"])]\n",
    "\n",
    "summary = (\n",
    "    df_filtered\n",
    "    .groupby(\"location\")\n",
    "    .agg(\n",
    "        geometry=(\"geometry\", \"first\"),\n",
    "        pre_date=(\"date\", lambda x: sorted(x[df_filtered.loc[x.index, \"event_type\"] == \"pre\"])[0] if any(df_filtered.loc[x.index, \"event_type\"] == \"pre\") else None),\n",
    "        post_date=(\"date\", lambda x: sorted(x[df_filtered.loc[x.index, \"event_type\"] == \"post\"])[0] if any(df_filtered.loc[x.index, \"event_type\"] == \"post\") else None),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "if isinstance(summary[\"geometry\"].iloc[0], str):\n",
    "    summary[\"geometry\"] = summary[\"geometry\"].apply(loads)\n",
    "summary_gdf = gpd.GeoDataFrame(summary, geometry=summary[\"geometry\"], crs=\"EPSG:4326\")\n",
    "summary_gdf[\"pre_date\"] = pd.to_datetime(summary_gdf[\"pre_date\"])\n",
    "summary_gdf[\"post_date\"] = pd.to_datetime(summary_gdf[\"post_date\"])\n",
    "\n",
    "mask_paths = (\n",
    "    fire_df[fire_df[\"event_type\"] == \"mask\"]\n",
    "    .groupby(\"location\")[\"path\"]\n",
    "    .first()  #one fire mask per location\n",
    "    .reset_index()\n",
    "    .rename(columns={\"path\": \"mask_path\"})\n",
    ")\n",
    "summary_gdf = summary_gdf.merge(mask_paths, on=\"location\", how=\"left\")\n",
    "\n",
    "summary_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b6ff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()#(n_workers=8, threads_per_worker=2)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55071abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry = Retry(\n",
    "    total=10, backoff_factor=1, status_forcelist=[502, 503, 504], allowed_methods=None\n",
    ")\n",
    "stac_api_io = StacApiIO(max_retries=retry)\n",
    "\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    "    stac_io=stac_api_io\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e069bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fire_mask = rioxarray.open_rasterio(\"/workspace/Rufai/data/S2-WCD/Almonaster/cm/cm.tif\", masked=True).squeeze()\n",
    "# fire_mask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35631f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fire_mask.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40b7b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from datetime import timedelta\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import calendar\n",
    "\n",
    "def get_date_ranges(row):\n",
    "    post_date = row[\"post_date\"]\n",
    "    # Define the event year\n",
    "    event_year = post_date.year\n",
    "\n",
    "    # Define quarterly ranges but ensure at least one includes the post_date\n",
    "    month_windows = [(12, 2), (3, 5), (6, 8), (9, 11)]\n",
    "    event_ranges = []\n",
    "\n",
    "    for start_month, end_month in month_windows:\n",
    "        if start_month == 12 and end_month == 2:\n",
    "            # December of previous year to February of event year\n",
    "            start_year = event_year - 1\n",
    "            end_year = event_year\n",
    "        else:\n",
    "            start_year = end_year = event_year\n",
    "        \n",
    "        start_day = f\"{start_year}-{str(start_month).zfill(2)}-01\"\n",
    "        end_day = f\"{end_year}-{str(end_month).zfill(2)}-{calendar.monthrange(end_year, end_month)[1]}\"\n",
    "        range_str = f\"{start_day}/{end_day}\"\n",
    "\n",
    "        # Always include windows that are after post_date\n",
    "        range_start_date = pd.to_datetime(start_day)\n",
    "        if range_start_date >= post_date or (start_month <= post_date.month <= end_month):\n",
    "            event_ranges.append(range_str)\n",
    "\n",
    "    # For control years, replicate those same month windows in each previous year\n",
    "    control_date_ranges = []\n",
    "    for delta_year in range(1, 8):\n",
    "        control_year = event_year - delta_year\n",
    "        control_year_ranges = []\n",
    "        for r in event_ranges:\n",
    "            start, end = r.split('/')\n",
    "            control_start = pd.to_datetime(start).replace(year=control_year).strftime(\"%Y-%m-%d\")\n",
    "            control_end = pd.to_datetime(end).replace(year=control_year).strftime(\"%Y-%m-%d\")\n",
    "            control_year_ranges.append(f\"{control_start}/{control_end}\")\n",
    "        control_date_ranges.append(control_year_ranges)\n",
    "\n",
    "    return event_ranges, control_date_ranges\n",
    "\n",
    "\n",
    "def rasterize_aoi(aoi, s2_stack):\n",
    "    \"\"\"\n",
    "    Rasterize the AOI polygon into a burn mask\n",
    "    \"\"\"\n",
    "\n",
    "    aoi_gdf = gpd.GeoDataFrame(\n",
    "        {\"geometry\": [shape(aoi['geometry'])]},\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    aoi_proj = aoi_gdf.to_crs(s2_stack.rio.crs)\n",
    "    \n",
    "    burn_mask = rasterize(\n",
    "        [(mapping(aoi_proj['geometry'].iloc[0]), 1)],\n",
    "        out_shape=(s2_stack.sizes['y'], s2_stack.sizes['x']),\n",
    "        transform=s2_stack.rio.transform(),\n",
    "        fill=0,\n",
    "        dtype='uint8'\n",
    "    )\n",
    "    \n",
    "    burn_mask_da = xr.DataArray(\n",
    "        burn_mask,\n",
    "        coords={\"y\": s2_stack[\"y\"], \"x\": s2_stack[\"x\"]},\n",
    "        dims=(\"y\", \"x\")\n",
    "    )\n",
    "\n",
    "    return burn_mask_da\n",
    "\n",
    "\n",
    "\n",
    "def read_fire_mask_from_file(mask_path, s2_stack):\n",
    "    # Read fire mask as DataArray with CRS support\n",
    "    fire_mask = rioxarray.open_rasterio(mask_path, masked=True).squeeze()\n",
    "    # Ensure mask has a CRS\n",
    "    if fire_mask.rio.crs is None:\n",
    "        raise ValueError(f\"Fire mask at {mask_path} has no CRS defined.\")\n",
    "    # Reproject and align to match S2 stack\n",
    "    fire_mask_matched = fire_mask.rio.reproject_match(s2_stack)\n",
    "\n",
    "    return fire_mask_matched\n",
    "\n",
    "\n",
    "def crop_burn_window(s2_stack, burn_mask, config):\n",
    "    \n",
    "    window_size = config['chips']['chip_size']\n",
    "\n",
    "    # Apply uniform filter (mean filter), then scale to get sum\n",
    "    burn_mean = uniform_filter(burn_mask.values.astype(float), size=window_size, mode='constant', cval=0.0)\n",
    "    burn_sum = burn_mean * (window_size ** 2)\n",
    "    \n",
    "    # Find maximum sum\n",
    "    max_idx = np.unravel_index(np.argmax(burn_sum), burn_sum.shape)\n",
    "    y_idx, x_idx = max_idx\n",
    "    \n",
    "    # Calculate start indices\n",
    "    y_start = max(y_idx - window_size // 2, 0)\n",
    "    x_start = max(x_idx - window_size // 2, 0)\n",
    "        \n",
    "    cropped_stack = s2_stack.isel(\n",
    "        y=slice(y_start, y_start + window_size),\n",
    "        x=slice(x_start, x_start + window_size)\n",
    "    )\n",
    "    \n",
    "    return cropped_stack\n",
    "\n",
    "def harmonize_to_old(data):\n",
    "    \"\"\"\n",
    "    Harmonize new Sentinel-2 data to the old baseline.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: xarray.DataArray\n",
    "        A DataArray with four dimensions: time, band, y, x\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    harmonized: xarray.DataArray\n",
    "        A DataArray with all values harmonized to the old\n",
    "        processing baseline.\n",
    "    \"\"\"\n",
    "    cutoff = datetime(2022, 1, 25)\n",
    "    offset = 1000\n",
    "    bands = [\n",
    "        \"B01\",\n",
    "        \"B02\",\n",
    "        \"B03\",\n",
    "        \"B04\",\n",
    "        \"B05\",\n",
    "        \"B06\",\n",
    "        \"B07\",\n",
    "        \"B08\",\n",
    "        \"B8A\",\n",
    "        \"B09\",\n",
    "        \"B10\",\n",
    "        \"B11\",\n",
    "        \"B12\",\n",
    "    ]\n",
    "\n",
    "    old = data.sel(time=slice(cutoff))\n",
    "\n",
    "    to_process = list(set(bands) & set(data.band.data.tolist()))\n",
    "    new = data.sel(time=slice(cutoff, None)).drop_sel(band=to_process)\n",
    "\n",
    "    new_harmonized = data.sel(time=slice(cutoff, None), band=to_process).clip(offset)\n",
    "    new_harmonized -= offset\n",
    "\n",
    "    new = xr.concat([new, new_harmonized], \"band\").sel(band=data.band.data.tolist())\n",
    "    \n",
    "    return xr.concat([old, new], dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e8d969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fire_chips(s2_stack, aoi, config, time_series_type, epsg, index, metadata_df):\n",
    "    try:\n",
    "        s2_stack = s2_stack.compute()\n",
    "    except:\n",
    "        print(\"skipping the AOI for no S2 data\")\n",
    "\n",
    "    burn_mask = rasterize_aoi(aoi, s2_stack) # why not read the burn mask directly? \n",
    "    # burn_mask = read_fire_mask_from_file(aoi[\"mask_path\"], s2_stack)\n",
    "\n",
    "    try:\n",
    "        s2_stack_cropped = crop_burn_window(s2_stack, burn_mask, config)\n",
    "    except:\n",
    "        print(\"Cropping S2 stack failed; skipping AOI\")\n",
    "    \n",
    "    if s2_stack_cropped.shape[2] != 224 or s2_stack_cropped.shape[3] != 224:\n",
    "        print(f\"Skipping chip ID {index} for mismatch dimensions\")\n",
    "        \n",
    "        return False, metadata_df \n",
    "    \n",
    "    if missing_values(s2_stack_cropped, config['chips']['chip_size'], config['chips']['chip_size']):\n",
    "        print(f\"Skipping chip ID {index} for missing values\")\n",
    "        return False, metadata_df      \n",
    "    \n",
    "    s2_stack_cropped = harmonize_to_old(s2_stack_cropped)\n",
    "    \n",
    "    s2_stack_cropped = s2_stack_cropped.fillna(-999)\n",
    "    s2_stack_cropped = s2_stack_cropped.rio.write_nodata(-999)\n",
    "    s2_stack_cropped = s2_stack_cropped.astype(np.dtype(np.int16))\n",
    "    s2_stack_cropped = s2_stack_cropped.rename(\"s2\")\n",
    "\n",
    "    if time_series_type == \"event\":\n",
    "        for dt in s2_stack_cropped.time.values:\n",
    "            ts = pd.to_datetime(str(dt)) \n",
    "            s2_path = f\"data/fire_data/s2_{index:06}_e_{ts.strftime('%Y%m%d')}.tif\"\n",
    "            s2_stack_cropped.sel(time = dt).squeeze().rio.to_raster(s2_path)\n",
    "\n",
    "            metadata_df = pd.concat([pd.DataFrame([[index,\n",
    "                                                    ts.strftime('%Y%m%d'),\n",
    "                                                    f\"{index:06}_e_{ts.strftime('%Y%m%d')}\",\n",
    "                                                    \"event\",\n",
    "                                                    s2_stack_cropped.x[int(len(s2_stack_cropped.x)/2)].data,\n",
    "                                                    s2_stack_cropped.y[int(len(s2_stack_cropped.y)/2)].data,\n",
    "                                                    epsg]\n",
    "                                                  ],\n",
    "                                                  columns=metadata_df.columns\n",
    "                                                 ),\n",
    "                                     metadata_df],\n",
    "                                    ignore_index=True\n",
    "                                   )\n",
    "            \n",
    "    else:\n",
    "        dt = s2_stack_cropped.time.values[0]\n",
    "        ts = pd.to_datetime(str(dt)) \n",
    "        s2_path = f\"data/fire_data/s2_{index:06}_c_{ts.strftime('%Y%m%d')}.tif\"\n",
    "        s2_stack_cropped.sel(time = dt).squeeze().rio.to_raster(s2_path)\n",
    "        metadata_df = pd.concat([pd.DataFrame([[index,\n",
    "                                                ts.strftime('%Y%m%d'),\n",
    "                                                f\"{index:06}_c_{ts.strftime('%Y%m%d')}\",\n",
    "                                                \"control\",\n",
    "                                                s2_stack_cropped.x[int(len(s2_stack_cropped.x)/2)].data,\n",
    "                                                s2_stack_cropped.y[int(len(s2_stack_cropped.y)/2)].data,\n",
    "                                                epsg]\n",
    "                                              ],\n",
    "                                      columns=metadata_df.columns\n",
    "                                     ),\n",
    "                         metadata_df],\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "\n",
    "    return True, metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0442003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.DataFrame(columns=[\"chip_id\", \"date\", \"sample_id\", \"type\", \"x_center\", \"y_center\", \"epsg\"])\n",
    "# metadata_df = pd.read_csv(\"data/metadata_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5bf03d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing AOI at index 0\n",
      "\n",
      "Processing AOI at index 1\n",
      "Skipping chip ID 1 for missing values\n",
      "\n",
      "Processing AOI at index 2\n",
      "Skipping chip ID 2 for missing values\n",
      "\n",
      "Processing AOI at index 3\n",
      "Skipping chip ID 3 for missing values\n",
      "\n",
      "Processing AOI at index 4\n",
      "Skipping chip ID 4 for missing values\n",
      "\n",
      "Processing AOI at index 5\n",
      "Skipping chip ID 5 for missing values\n",
      "\n",
      "Processing AOI at index 6\n",
      "Skipping chip ID 6 for missing values\n",
      "\n",
      "Processing AOI at index 7\n",
      "\n",
      "Processing AOI at index 8\n",
      "Skipping chip ID 8 for missing values\n",
      "\n",
      "Processing AOI at index 9\n",
      "Missing Sentinel-2 scenes for AOI (-0.3022279953603219, 38.787349583081784, -0.1977485520888272, 38.82807764488892)\n",
      "\n",
      "Processing AOI at index 10\n",
      "Missing Sentinel-2 scenes for AOI (-4.057573790038135, 41.03112188063114, -3.9300354295976905, 41.12805034396455)\n",
      "\n",
      "Processing AOI at index 11\n",
      "Missing Sentinel-2 scenes for AOI (-3.7992271949845042, 41.14634551157562, -3.704587757944652, 41.24256398914331)\n",
      "\n",
      "Processing AOI at index 12\n",
      "Missing Sentinel-2 scenes for AOI (-4.054725122484421, 40.82223856725514, -3.9273396113612162, 40.91872735160403)\n",
      "\n",
      "Processing AOI at index 13\n",
      "Missing Sentinel-2 scenes for AOI (-3.9284453090499025, 40.83973381697725, -3.8874163850573806, 40.918872200936605)\n",
      "\n",
      "Processing AOI at index 14\n",
      "Skipping chip ID 14 for missing values\n",
      "Skipping chip ID 14 for missing values\n",
      "Skipping chip ID 14 for missing values\n",
      "Skipping chip ID 14 for missing values\n",
      "Skipping chip ID 14 for missing values\n",
      "Skipping chip ID 14 for missing values\n",
      "Skipping chip ID 14 for missing values\n",
      "\n",
      "Processing AOI at index 15\n",
      "\n",
      "Processing AOI at index 16\n",
      "Skipping chip ID 16 for missing values\n",
      "Skipping chip ID 16 for missing values\n",
      "Skipping chip ID 16 for missing values\n",
      "Skipping chip ID 16 for missing values\n",
      "Skipping chip ID 16 for missing values\n",
      "\n",
      "Processing AOI at index 17\n",
      "\n",
      "Processing AOI at index 18\n",
      "Missing Sentinel-2 scenes for AOI (-5.2072356042078045, 36.45250735142733, -5.112653921198176, 36.54715200167686)\n",
      "\n",
      "Processing AOI at index 19\n",
      "\n",
      "Processing AOI at index 20\n",
      "Missing Sentinel-2 scenes for AOI (-3.658406777165725, 36.849686350068495, -3.5384926862516632, 36.91827869878824)\n",
      "\n",
      "Processing AOI at index 21\n",
      "Skipping chip ID 21 for missing values\n",
      "\n",
      "Processing AOI at index 22\n",
      "Skipping chip ID 22 for missing values\n",
      "\n",
      "Processing AOI at index 23\n",
      "Skipping chip ID 23 for missing values\n",
      "Skipping chip ID 23 for missing values\n",
      "Skipping chip ID 23 for missing values\n",
      "Skipping chip ID 23 for missing values\n",
      "Skipping chip ID 23 for missing values\n",
      "Skipping chip ID 23 for missing values\n",
      "Skipping chip ID 23 for missing values\n",
      "\n",
      "Processing AOI at index 24\n",
      "Skipping chip ID 24 for missing values\n",
      "Skipping chip ID 24 for missing values\n",
      "\n",
      "Processing AOI at index 25\n",
      "Skipping chip ID 25 for missing values\n",
      "Missing Sentinel-2 scenes for AOI (-0.8163074749904176, 38.94475875115965, -0.7686911103375568, 39.00690817957181)\n",
      "\n",
      "Processing AOI at index 26\n",
      "Skipping chip ID 26 for missing values\n",
      "\n",
      "Processing AOI at index 27\n",
      "Skipping chip ID 27 for missing values\n",
      "\n",
      "Processing AOI at index 28\n",
      "Missing Sentinel-2 scenes for AOI (-2.3187179918458747, 37.671897301541236, -2.197395534740468, 37.73447321984702)\n",
      "\n",
      "Processing AOI at index 29\n",
      "Missing Sentinel-2 scenes for AOI (-2.2190414576206927, 37.60822411428109, -2.110430231473165, 37.6720290825899)\n",
      "\n",
      "Processing AOI at index 30\n",
      "Missing Sentinel-2 scenes for AOI (-2.4393912701072593, 37.672657441074584, -2.3182443952229885, 37.72909253136081)\n",
      "\n",
      "Processing AOI at index 31\n",
      "Missing Sentinel-2 scenes for AOI (-2.4024017973118967, 37.646518441777594, -2.3187179918458747, 37.673110561289256)\n",
      "\n",
      "Processing AOI at index 32\n",
      "Skipping chip ID 32 for missing values\n",
      "\n",
      "Processing AOI at index 33\n",
      "Skipping chip ID 33 for missing values\n",
      "\n",
      "Processing AOI at index 34\n",
      "Skipping chip ID 34 for missing values\n",
      "\n",
      "Processing AOI at index 35\n",
      "Skipping chip ID 35 for missing values\n",
      "\n",
      "Processing AOI at index 36\n",
      "Skipping chip ID 36 for missing values\n",
      "\n",
      "Processing AOI at index 37\n",
      "Missing Sentinel-2 scenes for AOI (-4.59633232641112, 28.286228897096883, -4.486958228008655, 28.368195761289144)\n",
      "\n",
      "Processing AOI at index 38\n",
      "Missing Sentinel-2 scenes for AOI (-4.483910849072196, 28.37221514734265, -4.375089081466313, 28.454556923481675)\n",
      "\n",
      "Processing AOI at index 39\n",
      "Skipping chip ID 39 for missing values\n",
      "\n",
      "Processing AOI at index 40\n",
      "Skipping chip ID 40 for missing values\n",
      "Skipping chip ID 40 for missing values\n",
      "Skipping chip ID 40 for missing values\n"
     ]
    }
   ],
   "source": [
    "for index, aoi in summary_gdf.iterrows():\n",
    "    print(f\"\\nProcessing AOI at index {index}\")\n",
    "\n",
    "    aoi_bounds = aoi['geometry'].bounds\n",
    "    s2_items = pystac.item_collection.ItemCollection([])\n",
    "    event_date_ranges, control_date_ranges = get_date_ranges(aoi)\n",
    "    for date_range in event_date_ranges:        \n",
    "        s2_items_season = search_s2_scenes(aoi, date_range, catalog, config)\n",
    "        s2_items += s2_items_season\n",
    "\n",
    "    if len(s2_items)<2:\n",
    "        print(f\"Missing Sentinel-2 scenes for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "        \n",
    "\n",
    "    s2_stack = stack_s2_data(s2_items, config)\n",
    "    if s2_stack is None:\n",
    "        print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        epsg = s2_items[0].properties[\"proj:epsg\"]\n",
    "    except:\n",
    "        epsg = int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])\n",
    "\n",
    "    clipping_geom = aoi[\"geometry\"]\n",
    "\n",
    "    try:\n",
    "        s2_stack = stackstac.stack(\n",
    "            s2_items,\n",
    "            assets=config[\"sentinel_2\"][\"bands\"],\n",
    "            epsg=epsg,\n",
    "            resolution=config[\"sentinel_2\"][\"resolution\"],\n",
    "            fill_value=np.nan,\n",
    "            bounds_latlon = clipping_geom.bounds\n",
    "        )\n",
    "        s2_stack = mask_cloudy_pixels(s2_stack)\n",
    "        s2_stack = s2_stack.drop_sel(band=\"SCL\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error stacking Sentinel-2 data: {e}. Skipping AOI {index}\")\n",
    "        continue\n",
    "\n",
    "    event_status, metadata_df = generate_fire_chips(s2_stack, aoi, config, \"event\", epsg, index, metadata_df)\n",
    "    if event_status:\n",
    "        for control_date_range in control_date_ranges:\n",
    "            s2_items = search_s2_scenes(aoi, control_date_range[0], catalog, config)\n",
    "            \n",
    "            if len(s2_items)<1:\n",
    "                print(f\"Missing Sentinel-2 scenes for AOI {aoi_bounds}\")\n",
    "                continue\n",
    "        \n",
    "            s2_stack = stack_s2_data(s2_items, config)\n",
    "            if s2_stack is None:\n",
    "                print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds} in control year\")\n",
    "                continue\n",
    "            try:\n",
    "                epsg = s2_items[0].properties[\"proj:epsg\"]\n",
    "            except:\n",
    "                epsg = int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])\n",
    "            \n",
    "            try:\n",
    "                s2_stack = stackstac.stack(\n",
    "                    s2_items,\n",
    "                    assets=config[\"sentinel_2\"][\"bands\"],\n",
    "                    epsg=epsg,\n",
    "                    resolution=config[\"sentinel_2\"][\"resolution\"],\n",
    "                    fill_value=np.nan,\n",
    "                    bounds_latlon = clipping_geom.bounds\n",
    "                )\n",
    "                s2_stack = mask_cloudy_pixels(s2_stack)\n",
    "                s2_stack = s2_stack.drop_sel(band=\"SCL\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error stacking Sentinel-2 data: {e}. Skipping AOI {index}\")\n",
    "                continue\n",
    "        \n",
    "            control_status, metadata_df = generate_fire_chips(s2_stack, aoi, config, \"control\", epsg, index, metadata_df)\n",
    "    \n",
    "    metadata_df.to_csv('data/metadata_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "792277d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-06-01/2022-08-31', '2022-09-01/2022-11-30']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_date_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c10d6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2021-06-01/2021-08-31', '2021-09-01/2021-11-30'],\n",
       " ['2020-06-01/2020-08-31', '2020-09-01/2020-11-30'],\n",
       " ['2019-06-01/2019-08-31', '2019-09-01/2019-11-30'],\n",
       " ['2018-06-01/2018-08-31', '2018-09-01/2018-11-30'],\n",
       " ['2017-06-01/2017-08-31', '2017-09-01/2017-11-30'],\n",
       " ['2016-06-01/2016-08-31', '2016-09-01/2016-11-30'],\n",
       " ['2015-06-01/2015-08-31', '2015-09-01/2015-11-30']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_date_ranges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfm_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
