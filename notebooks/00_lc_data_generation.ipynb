{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f14eaaa-629f-43e3-b30d-7caad00396ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f75cc4-7bf6-4756-984a-e96faee36199",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d35a06f-f775-4889-8432-25a759078c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "import pystac\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3 import Retry\n",
    "from pystac_client.stac_api_io import StacApiIO\n",
    "import planetary_computer\n",
    "import warnings\n",
    "import dask.distributed\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from src.utils import search_s2_scenes, search_s1_scenes, search_landsat_scenes, search_dem_scene, search_lc_scene \n",
    "from src.utils import stack_data, stack_dem_data, stack_lc_data, unique_class, missing_values, gen_chips\n",
    "import yaml\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from functools import reduce\n",
    "from shapely import box\n",
    "from src.lc_generation import pystac_itemcollection_to_gdf, process_aoi\n",
    "from src.lc_generation import process_chips, process_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2246f54c-8a84-43f9-9ebc-93ce78064dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/home/benchuser/code/config.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ecdec4-a210-46fc-95da-e8cafcb1b5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:33627/status\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"distributed\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"dask\").setLevel(logging.ERROR)\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "version = config['dataset']['version']\n",
    "working_dir = Path(config['working_dir'])\n",
    "output_dir = Path(config['output_dir'])\n",
    "(working_dir / version).mkdir(exist_ok=True)\n",
    "metadata_filename = config['metadata']['file']\n",
    "aoi_version = config['aoi']['version']\n",
    "\n",
    "(working_dir / version).mkdir(exist_ok=True)\n",
    "shutil.copy(config_path, working_dir / version / \"config.yaml\")\n",
    "\n",
    "\n",
    "cluster = LocalCluster(silence_logs=logging.ERROR)\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)\n",
    "\n",
    "retry = Retry(\n",
    "    total=10, backoff_factor=1, status_forcelist=[502, 503, 504], allowed_methods=None\n",
    ")\n",
    "stac_api_io = StacApiIO(max_retries=retry)\n",
    "\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    "    stac_io=stac_api_io\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    aoi_path = (working_dir / version / f'{aoi_version}.geojson')\n",
    "    aoi_gdf = gpd.read_file(aoi_path)\n",
    "    metadata_df = pd.read_csv(working_dir / version / metadata_filename)\n",
    "    global_index = metadata_df['chip_id'].max() + 1\n",
    "except: \n",
    "    aoi_path = (f'/home/benchuser/code/data/map_{aoi_version}.geojson')\n",
    "    aoi_gdf = gpd.read_file(aoi_path)\n",
    "    aoi_gdf['processed'] = False\n",
    "    aoi_gdf = aoi_gdf.drop(config['excluded_aoi_indices'])\n",
    "    aoi_gdf.to_file(working_dir / version / f'{aoi_version}.geojson', driver = 'GeoJSON')\n",
    "    metadata_df = pd.DataFrame(columns=[\"chip_id\", \"aoi_index\", \"s2_dates\", \"s1_dates\", \"landsat_dates\", \"lc\", \"x_center\", \"y_center\", \"epsg\"])\n",
    "    global_index = 0\n",
    "\n",
    "aoi_path = working_dir / version / f'{aoi_version}.geojson'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a30cbc5-b6cb-44af-a2e2-48f33b5f3fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "Processing AOI at index 0\n",
      "Searching Sentinel-2 scenes for 2023-01-01/2023-03-31\n",
      "Searching Sentinel-2 scenes for 2023-04-01/2023-06-30\n",
      "Searching Sentinel-2 scenes for 2023-07-01/2023-09-30\n",
      "Searching Sentinel-2 scenes for 2023-10-01/2023-12-31\n",
      "Searching Sentinel-1 and Landsat scenes close to 2023-02-18 08:50:21.024000+00:00\n",
      "Searching Sentinel-1 and Landsat scenes close to 2023-04-19 08:46:01.024000+00:00\n",
      "Searching Sentinel-1 and Landsat scenes close to 2023-07-13 08:46:49.024000+00:00\n",
      "Searching Sentinel-1 and Landsat scenes close to 2023-12-30 08:52:59.024000+00:00\n",
      "Missing Landsat Scenes for AOI (21.64939395002699, 3.454672956621337, 21.73536917846863, 3.533747561055719)\n",
      "1\n",
      "\n",
      "Processing AOI at index 1\n",
      "Searching Sentinel-2 scenes for 2023-01-01/2023-03-31\n",
      "Searching Sentinel-2 scenes for 2023-04-01/2023-06-30\n",
      "Searching Sentinel-2 scenes for 2023-07-01/2023-09-30\n",
      "Searching Sentinel-2 scenes for 2023-10-01/2023-12-31\n",
      "Searching Sentinel-1 and Landsat scenes close to 2023-02-16 08:59:39.024000+00:00\n",
      "Searching Sentinel-1 and Landsat scenes close to 2023-04-07 08:55:59.024000+00:00\n",
      "Searching Sentinel-1 and Landsat scenes close to 2023-07-01 08:56:01.024000+00:00\n",
      "Searching Sentinel-1 and Landsat scenes close to 2023-12-18 09:04:01.024000+00:00\n",
      "searching Land Cover data...\n",
      "searching DEM data...\n",
      "stacking Landsat data...\n",
      "stacking Sentinel-2 data...\n",
      "stacking DEM data...\n",
      "('y', 'x')\n",
      "stacking Land Cover data...\n",
      "stacking Sentinel-1 data...\n"
     ]
    }
   ],
   "source": [
    "for index, aoi in aoi_gdf.iterrows():\n",
    "    print(index)\n",
    "    \n",
    "    print(f\"\\nProcessing AOI at index {index}\")\n",
    "    \n",
    "    aoi_bounds = aoi['geometry'].bounds\n",
    "    s2_items = pystac.item_collection.ItemCollection([])\n",
    "    \n",
    "    for date_range in config[\"sentinel_2\"][\"time_ranges\"]:   \n",
    "        print(f\"Searching Sentinel-2 scenes for {date_range}\")\n",
    "        s2_items_season = search_s2_scenes(aoi, date_range, catalog, config)\n",
    "        s2_items += s2_items_season\n",
    "    \n",
    "    if len(s2_items)<4:\n",
    "        print(f\"Missing Sentinel-2 scenes for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        epsg = s2_items[0].properties[\"proj:epsg\"]\n",
    "    except:\n",
    "        epsg = int(s2_items[0].properties[\"proj:code\"].split(\":\")[-1])\n",
    "    bbox_latlon = s2_items[0].bbox\n",
    "    \n",
    "    s1_items = pystac.item_collection.ItemCollection([])\n",
    "    landsat_items = pystac.item_collection.ItemCollection([])\n",
    "    \n",
    "    for s2_item in s2_items:\n",
    "        s2_datetime = s2_item.datetime\n",
    "        print(f\"Searching Sentinel-1 and Landsat scenes close to {s2_datetime}\")\n",
    "        s1_item = search_s1_scenes(aoi, s2_datetime, catalog, config)\n",
    "        s1_items += s1_item\n",
    "        landsat_item = search_landsat_scenes(aoi, s2_datetime, catalog, config)\n",
    "        landsat_items += landsat_item\n",
    "    \n",
    "    if len(landsat_items) < 4:\n",
    "        print(f\"Missing Landsat Scenes for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "    \n",
    "    if len(s1_items) < 4:\n",
    "        print(f\"Missing S1 scenes for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "            \n",
    "    print(\"searching Land Cover data...\")\n",
    "    lc_items = search_lc_scene(aoi, catalog, config)\n",
    "    if not lc_items:\n",
    "        print(f\"No Land Cover data found for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "    \n",
    "    print(\"searching DEM data...\")\n",
    "    dem_items = search_dem_scene(aoi, catalog, config)\n",
    "    if not dem_items:\n",
    "        print(f\"No DEM data found for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "    \n",
    "        # first, get area of overlap of all item bboxes\n",
    "    itemcollections = [s2_items, s1_items, landsat_items, lc_items, dem_items]\n",
    "    bbox_gdf = pd.concat([pystac_itemcollection_to_gdf(items) for items in itemcollections])\n",
    "    combined_geoms = bbox_gdf.groupby('collection')['geometry'].apply(lambda x: x.unary_union)\n",
    "    overlap = reduce(lambda x, y: x.intersection(y), combined_geoms)\n",
    "    overlap_bounds = overlap.bounds\n",
    "    \n",
    "    print(\"stacking Landsat data...\")\n",
    "    landsat_stack = stack_data(landsat_items, \"landsat\", config, epsg, overlap_bounds, bbox_is_latlon=True)\n",
    "    if landsat_stack is None:\n",
    "        print(f\"Failed to stack Landsat bands for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "    \n",
    "    overlap_bbox = landsat_stack.rio.bounds()\n",
    "    \n",
    "    print(\"stacking Sentinel-2 data...\")\n",
    "    s2_stack = stack_data(s2_items, \"sentinel_2\", config, epsg, overlap_bounds, bbox_is_latlon=True)\n",
    "    if s2_stack is None:\n",
    "        print(f\"Failed to stack Sentinel-2 bands for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "    \n",
    "    print(\"stacking DEM data...\")\n",
    "    dem_stack = stack_dem_data(dem_items, config,  epsg, overlap_bounds, bbox_is_latlon=True)\n",
    "    if dem_stack is None:\n",
    "        print(f\"Failed to stack DEM data for AOI {aoi_bounds} and date range {date_range}\")\n",
    "        continue\n",
    "        \n",
    "    print(\"stacking Land Cover data...\")\n",
    "    lc_stack = stack_lc_data(lc_items, config, epsg, overlap_bbox)\n",
    "    if lc_stack is None:\n",
    "        print(f\"Failed to stack Land Cover data for AOI {aoi_bounds} and date range {date_range}\")\n",
    "        continue\n",
    "    \n",
    "    print(\"stacking Sentinel-1 data...\")\n",
    "    s1_stack = stack_data(s1_items, \"sentinel_1\", config, epsg, overlap_bounds, bbox_is_latlon=True)\n",
    "    if s1_stack is None:\n",
    "        print(f\"Failed to stack Sentinel-1 bands for AOI {aoi_bounds}\")\n",
    "        continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be614d25-6266-406c-986a-66a1a979966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process array\n",
    "\n",
    "print(\"Loading lc_stack\")\n",
    "\n",
    "try:\n",
    "    lc_stack = lc_stack.compute()\n",
    "except:\n",
    "    print(\"skipping the AOI for no LC data\")\n",
    "\n",
    "print(\"Loading s2_stack\")\n",
    "\n",
    "try:\n",
    "    s2_stack = s2_stack.compute()\n",
    "except:\n",
    "    print(\"skipping the AOI for no S2 data\")\n",
    "\n",
    "print(\"Loading s1_stack\")\n",
    "\n",
    "try:\n",
    "    s1_stack = s1_stack.compute()\n",
    "except:\n",
    "    print(\"skipping the AOI for no S1 data\")\n",
    "\n",
    "print(\"Loading dem_stack\")\n",
    "\n",
    "try:\n",
    "    dem_stack = dem_stack.compute()\n",
    "except:\n",
    "    print(\"skipping the AOI for no dem data\")\n",
    "\n",
    "try:\n",
    "    landsat_stack = landsat_stack.compute()\n",
    "except:\n",
    "    print(\"skipping the AOI for no landsat data\")\n",
    "\n",
    "lc_sample_size = int(config['chips']['sample_size'] / config['land_cover']['resolution'])\n",
    "\n",
    "lc_uniqueness = lc_stack.coarsen(x = lc_sample_size,\n",
    "                                 y = lc_sample_size,\n",
    "                                 boundary = \"trim\"\n",
    "                                ).reduce(unique_class)\n",
    "lc_uniqueness[0:2, :] = False\n",
    "lc_uniqueness[-2:, :] = False\n",
    "lc_uniqueness[:, 0:2] = False\n",
    "lc_uniqueness[:, -2:] = False\n",
    "\n",
    "ys, xs = np.where(lc_uniqueness)\n",
    "\n",
    "# Following indices are added to limit the number of rangeland, bareground, and water chips per tile\n",
    "rangeland_index = 0\n",
    "bareground_index = 0\n",
    "water_index = 0\n",
    "tree_index = 0\n",
    "crops_index = 0\n",
    "for index in range(0, len(ys)):\n",
    "    x = xs[index]\n",
    "    y = ys[index]\n",
    "    \n",
    "    \n",
    "    s2_array = process_array(\n",
    "        stack = s2_stack, \n",
    "        epsg = epsg, \n",
    "        coords = (x, y),\n",
    "        array_name = 'sentinel_2',\n",
    "        config = config,\n",
    "        fill_na = False, # so we can check for missing values\n",
    "        na_value = None,\n",
    "        dtype = np.int16,\n",
    "    )\n",
    "\n",
    "    if len(s2_array.time.values) < 4:\n",
    "        print(\"Missing scenes in S2 array\")\n",
    "        continue\n",
    "    \n",
    "    if s2_array is None:\n",
    "        print(\"Missing values in S2 array\")\n",
    "        continue    \n",
    "\n",
    "    s1_array = process_array(\n",
    "        stack = s1_stack, \n",
    "        epsg = epsg, \n",
    "        coords = (x, y),\n",
    "        array_name = 'sentinel_1',\n",
    "        config = config,\n",
    "        fill_na = False,\n",
    "        na_value = None,\n",
    "        dtype = np.float32,\n",
    "    )\n",
    "\n",
    "    if s1_array is None:\n",
    "        print(\"Missing values in S1 array\")\n",
    "        continue \n",
    "\n",
    "    if len(s2_array.time.values) < 4:\n",
    "        print(\"Missing scenes in S1 array\")\n",
    "        continue\n",
    "\n",
    "    landsat_array = process_array(\n",
    "        stack = landsat_stack, \n",
    "        epsg = epsg, \n",
    "        coords = (x, y),\n",
    "        array_name = 'landsat',\n",
    "        config = config,\n",
    "        fill_na = False,\n",
    "        na_value = None,\n",
    "        dtype = np.float32,\n",
    "    )\n",
    "\n",
    "    if landsat_array is None:\n",
    "        print(\"Missing values in landsat array\")\n",
    "        continue \n",
    "\n",
    "    if len(s2_array.time.values) < 4:\n",
    "        print(\"Missing scenes in landsat array\")\n",
    "        continue\n",
    "\n",
    "    lc_array = process_array(\n",
    "        stack = lc_stack, \n",
    "        epsg = epsg, \n",
    "        coords = (x, y),\n",
    "        array_name = 'land_cover',\n",
    "        config = config,\n",
    "        fill_na = False,\n",
    "        na_value = None,\n",
    "        dtype = np.int8,\n",
    "    )\n",
    "    \n",
    "    if lc_array is None:\n",
    "        print(\"Missing values in land cover array\")\n",
    "        continue\n",
    "        \n",
    "    dem_array = process_array(\n",
    "        stack = dem_stack, \n",
    "        epsg = epsg, \n",
    "        coords = (x, y),\n",
    "        array_name = 'dem',\n",
    "        config = config,\n",
    "        fill_na = False,\n",
    "        na_value = None,\n",
    "        dtype = np.float32,\n",
    "    )\n",
    "\n",
    "    if dem_array is None:\n",
    "        print(\"Missing values in dem array\")\n",
    "        continue\n",
    "        \n",
    "    if (np.isin(lc_array, [255, 130, 133])).any():\n",
    "        raise ValueError('Wrong LC value')\n",
    "    # Skipping Flooded Vegetation\n",
    "    if (np.isin(lc_array, [4])).any():\n",
    "        print(\"Skipping flooded vegetation\")\n",
    "        continue\n",
    "    \n",
    "    lc = np.unique(lc_array)\n",
    "    if lc == 1:\n",
    "        water_index += 1\n",
    "        if water_index > 400:\n",
    "            continue \n",
    "    elif lc == 8:\n",
    "        bareground_index += 1\n",
    "        if bareground_index > 400:\n",
    "            continue\n",
    "    elif lc == 11:\n",
    "        rangeland_index += 1\n",
    "        if rangeland_index > 400:\n",
    "            continue\n",
    "    elif lc == 2:\n",
    "        tree_index += 1\n",
    "        if tree_index > 400:\n",
    "            continue\n",
    "    elif lc == 5:\n",
    "        crops_index += 1\n",
    "        if crops_index > 400:\n",
    "            continue\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
